{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8tQJd2YSCfWR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7tqLMoKF6uq"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 6\n",
    "------------\n",
    "\n",
    "After training a skip-gram model in `5_word2vec.ipynb`, the goal of this notebook is to train a LSTM character model over [Text8](http://mattmahoney.net/dc/textdata) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "MvEblsgEXxrd"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 5993,
     "status": "ok",
     "timestamp": 1445965582896,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "RJ-o3UBUFtCw",
    "outputId": "d530534e-0791-4a94-ca6d-1c8f1b908a9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified text8.zip\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mattmahoney.net/dc/'\n",
    "\n",
    "def maybe_download(filename, expected_bytes):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  if not os.path.exists(filename):\n",
    "    filename, _ = urlretrieve(url + filename, filename)\n",
    "  statinfo = os.stat(filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified %s' % filename)\n",
    "  else:\n",
    "    print(statinfo.st_size)\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "  return filename\n",
    "\n",
    "filename = maybe_download('text8.zip', 31344016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 5982,
     "status": "ok",
     "timestamp": 1445965582916,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "Mvf09fjugFU_",
    "outputId": "8f75db58-3862-404b-a0c3-799380597390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 100000000\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename):\n",
    "  f = zipfile.ZipFile(filename)\n",
    "  for name in f.namelist():\n",
    "    return tf.compat.as_str(f.read(name))\n",
    "  f.close()\n",
    "  \n",
    "text = read_data(filename)\n",
    "print('Data size %d' % len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ga2CYACE-ghb"
   },
   "source": [
    "Create a small validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 6184,
     "status": "ok",
     "timestamp": 1445965583138,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "w-oBpfFG-j43",
    "outputId": "bdb96002-d021-4379-f6de-a977924f0d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99999000 ons anarchists advocate social relations based upon voluntary as\n",
      "1000  anarchism originated as a term of abuse first used against earl\n"
     ]
    }
   ],
   "source": [
    "valid_size = 1000\n",
    "valid_text = text[:valid_size]\n",
    "train_text = text[valid_size:]\n",
    "train_size = len(train_text)\n",
    "print(train_size, train_text[:64])\n",
    "print(valid_size, valid_text[:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zdw6i4F8glpp"
   },
   "source": [
    "Utility functions to map characters to vocabulary IDs and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 6276,
     "status": "ok",
     "timestamp": 1445965583249,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "gAL1EECXeZsD",
    "outputId": "88fc9032-feb9-45ff-a9a0-a26759cc1f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected character: ï\n",
      "1 26 0 0\n",
      "a z  \n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(string.ascii_lowercase) + 1 # [a-z] + ' '\n",
    "first_letter = ord(string.ascii_lowercase[0])\n",
    "\n",
    "def char2id(char):\n",
    "  if char in string.ascii_lowercase:\n",
    "    return ord(char) - first_letter + 1\n",
    "  elif char == ' ':\n",
    "    return 0\n",
    "  else:\n",
    "    print('Unexpected character: %s' % char)\n",
    "    return 0\n",
    "  \n",
    "def id2char(dictid):\n",
    "  if dictid > 0:\n",
    "    return chr(dictid + first_letter - 1)\n",
    "  else:\n",
    "    return ' '\n",
    "\n",
    "print(char2id('a'), char2id('z'), char2id(' '), char2id('ï'))\n",
    "print(id2char(1), id2char(26), id2char(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFwoyygOmWsL"
   },
   "source": [
    "Function to generate a training batch for the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 6473,
     "status": "ok",
     "timestamp": 1445965583467,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "d9wMtjy5hCj9",
    "outputId": "3dd79c80-454a-4be0-8b71-4a4a357b3367"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ons anarchi', 'when milita', 'lleria arch', ' abbeys and', 'married urr', 'hel and ric', 'y and litur', 'ay opened f', 'tion from t', 'migration t', 'new york ot', 'he boeing s', 'e listed wi', 'eber has pr', 'o be made t', 'yer who rec', 'ore signifi', 'a fierce cr', ' two six ei', 'aristotle s', 'ity can be ', ' and intrac', 'tion of the', 'dy to pass ', 'f certain d', 'at it will ', 'e convince ', 'ent told hi', 'ampaign and', 'rver side s', 'ious texts ', 'o capitaliz', 'a duplicate', 'gh ann es d', 'ine january', 'ross zero t', 'cal theorie', 'ast instanc', ' dimensiona', 'most holy m', 't s support', 'u is still ', 'e oscillati', 'o eight sub', 'of italy la', 's the tower', 'klahoma pre', 'erprise lin', 'ws becomes ', 'et in a naz', 'the fabian ', 'etchy to re', ' sharman ne', 'ised empero', 'ting in pol', 'd neo latin', 'th risky ri', 'encyclopedi', 'fense the a', 'duating fro', 'treet grid ', 'ations more', 'appeal of d', 'si have mad']\n",
      "['ists advoca', 'ary governm', 'hes nationa', 'd monasteri', 'raca prince', 'chard baer ', 'rgical lang', 'for passeng', 'the nationa', 'took place ', 'ther well k', 'seven six s', 'ith a gloss', 'robably bee', 'to recogniz', 'ceived the ', 'icant than ', 'ritic of th', 'ight in sig', 's uncaused ', ' lost as in', 'cellular ic', 'e size of t', ' him a stic', 'drugs confu', ' take to co', ' the priest', 'im to name ', 'd barred at', 'standard fo', ' such as es', 'ze on the g', 'e of the or', 'd hiver one', 'y eight mar', 'the lead ch', 'es classica', 'ce the non ', 'al analysis', 'mormons bel', 't or at lea', ' disagreed ', 'ing system ', 'btypes base', 'anguages th', 'r commissio', 'ess one nin', 'nux suse li', ' the first ', 'zi concentr', ' society ne', 'elatively s', 'etworks sha', 'or hirohito', 'litical ini', 'n most of t', 'iskerdoo ri', 'ic overview', 'air compone', 'om acnm acc', ' centerline', 'e than any ', 'devotional ', 'de such dev']\n",
      "[' a']\n",
      "['an']\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "num_unrollings=10\n",
    "\n",
    "class BatchGenerator(object):\n",
    "  def __init__(self, text, batch_size, num_unrollings):\n",
    "    self._text = text\n",
    "    self._text_size = len(text)\n",
    "    self._batch_size = batch_size\n",
    "    self._num_unrollings = num_unrollings\n",
    "    segment = self._text_size // batch_size\n",
    "    self._cursor = [ offset * segment for offset in range(batch_size)]\n",
    "    self._last_batch = self._next_batch()\n",
    "  \n",
    "  def _next_batch(self):\n",
    "    \"\"\"Generate a single batch from the current cursor position in the data.\"\"\"\n",
    "    batch = np.zeros(shape=(self._batch_size, vocabulary_size), dtype=np.float)\n",
    "    for b in range(self._batch_size):\n",
    "      batch[b, char2id(self._text[self._cursor[b]])] = 1.0\n",
    "      self._cursor[b] = (self._cursor[b] + 1) % self._text_size\n",
    "    return batch\n",
    "  \n",
    "  def next(self):\n",
    "    \"\"\"Generate the next array of batches from the data. The array consists of\n",
    "    the last batch of the previous array, followed by num_unrollings new ones.\n",
    "    \"\"\"\n",
    "    batches = [self._last_batch]\n",
    "    for step in range(self._num_unrollings):\n",
    "      batches.append(self._next_batch())\n",
    "    self._last_batch = batches[-1]\n",
    "    return batches\n",
    "\n",
    "def characters(probabilities):\n",
    "  \"\"\"Turn a 1-hot encoding or a probability distribution over the possible\n",
    "  characters back into its (most likely) character representation.\"\"\"\n",
    "  return [id2char(c) for c in np.argmax(probabilities, 1)]\n",
    "\n",
    "def batches2string(batches):\n",
    "  \"\"\"Convert a sequence of batches back into their (most likely) string\n",
    "  representation.\"\"\"\n",
    "  s = [''] * batches[0].shape[0]\n",
    "  for b in batches:\n",
    "    s = [''.join(x) for x in zip(s, characters(b))]\n",
    "  return s\n",
    "\n",
    "train_batches = BatchGenerator(train_text, batch_size, num_unrollings)\n",
    "valid_batches = BatchGenerator(valid_text, 1, 1)\n",
    "\n",
    "print(batches2string(train_batches.next()))\n",
    "print(batches2string(train_batches.next()))\n",
    "print(batches2string(valid_batches.next()))\n",
    "print(batches2string(valid_batches.next()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "KyVd8FxT5QBc"
   },
   "outputs": [],
   "source": [
    "def logprob(predictions, labels):\n",
    "  \"\"\"Log-probability of the true labels in a predicted batch.\"\"\"\n",
    "  predictions[predictions < 1e-10] = 1e-10\n",
    "  return np.sum(np.multiply(labels, -np.log(predictions))) / labels.shape[0]\n",
    "\n",
    "def sample_distribution(distribution):\n",
    "  \"\"\"Sample one element from a distribution assumed to be an array of normalized\n",
    "  probabilities.\n",
    "  \"\"\"\n",
    "  r = random.uniform(0, 1)\n",
    "  s = 0\n",
    "  for i in range(len(distribution)):\n",
    "    s += distribution[i]\n",
    "    if s >= r:\n",
    "      return i\n",
    "  return len(distribution) - 1\n",
    "\n",
    "def sample(prediction):\n",
    "  \"\"\"Turn a (column) prediction into 1-hot encoded samples.\"\"\"\n",
    "  p = np.zeros(shape=[1, vocabulary_size], dtype=np.float)\n",
    "  p[0, sample_distribution(prediction[0])] = 1.0\n",
    "  return p\n",
    "\n",
    "def random_distribution():\n",
    "  \"\"\"Generate a random column of probabilities.\"\"\"\n",
    "  b = np.random.uniform(0.0, 1.0, size=[1, vocabulary_size])\n",
    "  return b/np.sum(b, 1)[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8f67YXaDr4C"
   },
   "source": [
    "Simple LSTM Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Q5rxZK6RDuGe"
   },
   "outputs": [],
   "source": [
    "num_nodes = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  \n",
    "  # Parameters:\n",
    "  # Input gate: input, previous output, and bias.\n",
    "  ix = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "  im = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  ib = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Forget gate: input, previous output, and bias.\n",
    "  fx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "  fm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  fb = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Memory cell: input, state and bias.                             \n",
    "  cx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "  cm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  cb = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Output gate: input, previous output, and bias.\n",
    "  ox = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "  om = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  ob = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Variables saving state across unrollings.\n",
    "  saved_output = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "  saved_state = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "  # Classifier weights and biases.\n",
    "  w = tf.Variable(tf.truncated_normal([num_nodes, vocabulary_size], -0.1, 0.1))\n",
    "  b = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "  \n",
    "  # Definition of the cell computation.\n",
    "  def lstm_cell(i, o, state):\n",
    "    \"\"\"Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n",
    "    Note that in this formulation, we omit the various connections between the\n",
    "    previous state and the gates.\"\"\"\n",
    "    input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n",
    "    forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n",
    "    update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n",
    "    state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "    output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n",
    "    return output_gate * tf.tanh(state), state\n",
    "\n",
    "  # Input data.\n",
    "  train_data = list()\n",
    "  for _ in range(num_unrollings + 1):\n",
    "    train_data.append(\n",
    "      tf.placeholder(tf.float32, shape=[batch_size,vocabulary_size]))\n",
    "  train_inputs = train_data[:num_unrollings]\n",
    "  train_labels = train_data[1:]  # labels are inputs shifted by one time step.\n",
    "\n",
    "  # Unrolled LSTM loop.\n",
    "  outputs = list()\n",
    "  output = saved_output\n",
    "  state = saved_state\n",
    "  for i in train_inputs:\n",
    "    output, state = lstm_cell(i, output, state)\n",
    "    outputs.append(output)\n",
    "\n",
    "  # State saving across unrollings.\n",
    "  with tf.control_dependencies([saved_output.assign(output),\n",
    "                                saved_state.assign(state)]):\n",
    "    # Classifier.\n",
    "    logits = tf.nn.xw_plus_b(tf.concat(0, outputs), w, b)\n",
    "    loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits, tf.concat(0, train_labels)))\n",
    "\n",
    "  # Optimizer.\n",
    "  global_step = tf.Variable(0)\n",
    "  learning_rate = tf.train.exponential_decay(\n",
    "    10.0, global_step, 5000, 0.1, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "  gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "  gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "  optimizer = optimizer.apply_gradients(\n",
    "    zip(gradients, v), global_step=global_step)\n",
    "\n",
    "  # Predictions.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  \n",
    "  # Sampling and validation eval: batch 1, no unrolling.\n",
    "  sample_input = tf.placeholder(tf.float32, shape=[1, vocabulary_size])\n",
    "  saved_sample_output = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  saved_sample_state = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  reset_sample_state = tf.group(\n",
    "    saved_sample_output.assign(tf.zeros([1, num_nodes])),\n",
    "    saved_sample_state.assign(tf.zeros([1, num_nodes])))\n",
    "  sample_output, sample_state = lstm_cell(\n",
    "    sample_input, saved_sample_output, saved_sample_state)\n",
    "  with tf.control_dependencies([saved_sample_output.assign(sample_output),\n",
    "                                saved_sample_state.assign(sample_state)]):\n",
    "    sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 41
      },
      {
       "item_id": 80
      },
      {
       "item_id": 126
      },
      {
       "item_id": 144
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 199909,
     "status": "ok",
     "timestamp": 1445965877333,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "RD9zQCZTEaEm",
    "outputId": "5e868466-2532-4545-ce35-b403cf5d9de6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-43c8b13f6a78>:5 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Average loss at step 0: 3.294009 learning rate: 10.000000\n",
      "Minibatch perplexity: 26.95\n",
      "================================================================================\n",
      "lc t sgsibhtlvlbmm leohxw g ywaginpe ygtct hlkrv fkonznzcvkj ymhwgmtizocooewiyd \n",
      "ksiol rdb ddaryoiishrxpdu r qiauh vz wiyziqyoe ervm thtarjqdph drmnohspu wt bdvm\n",
      "apaia js tslthv  eedkughqonoobozpowtoef wk ey rxndlu vvowgs s bzxettrarnd qelaj \n",
      "dsgmgvgemifeonttne mbwlscrhci  qrznheye q mqxudxn guleh vau aagltvlbry  skd hfnp\n",
      "lwqedfmayiiri afrd ynyel  oml cxqxr  tpfrwg gqkim dw ittmr earldsmi  bbx ghjthdm\n",
      "================================================================================\n",
      "Validation set perplexity: 20.28\n",
      "Average loss at step 100: 2.593676 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.86\n",
      "Validation set perplexity: 10.19\n",
      "Average loss at step 200: 2.245407 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.54\n",
      "Validation set perplexity: 8.44\n",
      "Average loss at step 300: 2.095258 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.52\n",
      "Validation set perplexity: 8.14\n",
      "Average loss at step 400: 1.997479 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.23\n",
      "Validation set perplexity: 7.75\n",
      "Average loss at step 500: 1.935522 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.40\n",
      "Validation set perplexity: 7.28\n",
      "Average loss at step 600: 1.910948 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.19\n",
      "Validation set perplexity: 7.02\n",
      "Average loss at step 700: 1.863283 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.53\n",
      "Validation set perplexity: 6.69\n",
      "Average loss at step 800: 1.823817 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.05\n",
      "Validation set perplexity: 6.51\n",
      "Average loss at step 900: 1.835388 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.94\n",
      "Validation set perplexity: 6.34\n",
      "Average loss at step 1000: 1.829906 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.59\n",
      "================================================================================\n",
      "tencioge ouf a prodelity brow to zero the its que create of enite as quat enet a\n",
      "pute pyeden tepleping are wores bist enoted two seven refich ocle alco was finur\n",
      "t jetwolod one noveved charistivile t onit nere four five six eight in may of th\n",
      "jo one nine chift fromle diever come natilar paintor lay to maly his dewori and \n",
      "ne elyed light willspents lifflee his ord eight be one seven zour the sounly und\n",
      "================================================================================\n",
      "Validation set perplexity: 6.23\n",
      "Average loss at step 1100: 1.779111 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.46\n",
      "Validation set perplexity: 5.92\n",
      "Average loss at step 1200: 1.759004 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.07\n",
      "Validation set perplexity: 5.68\n",
      "Average loss at step 1300: 1.740196 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.75\n",
      "Validation set perplexity: 5.69\n",
      "Average loss at step 1400: 1.747935 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.86\n",
      "Validation set perplexity: 5.60\n",
      "Average loss at step 1500: 1.740244 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.78\n",
      "Validation set perplexity: 5.34\n",
      "Average loss at step 1600: 1.749982 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.40\n",
      "Validation set perplexity: 5.47\n",
      "Average loss at step 1700: 1.714404 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.55\n",
      "Validation set perplexity: 5.41\n",
      "Average loss at step 1800: 1.678366 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.56\n",
      "Validation set perplexity: 5.27\n",
      "Average loss at step 1900: 1.643647 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.04\n",
      "Validation set perplexity: 5.16\n",
      "Average loss at step 2000: 1.694060 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.58\n",
      "================================================================================\n",
      "jeotep but acerop on suineal a one alich s in standing gove saves alcend s biff \n",
      " as altomerras thad one nine seisz to tellogat the ireatoe was tured be un the n\n",
      "s bassing gaine prassonautenter spo positing as first be smoft beconding is and \n",
      "gs repanitura the nobacts s idzitians an amqur s jain capple orcesions drom bepi\n",
      "ponaling micks one five and other is of mainals name fins hong thapia crakes of \n",
      "================================================================================\n",
      "Validation set perplexity: 5.25\n",
      "Average loss at step 2100: 1.684567 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.13\n",
      "Validation set perplexity: 5.00\n",
      "Average loss at step 2200: 1.683413 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.28\n",
      "Validation set perplexity: 5.00\n",
      "Average loss at step 2300: 1.642964 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.15\n",
      "Validation set perplexity: 4.86\n",
      "Average loss at step 2400: 1.660460 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.09\n",
      "Validation set perplexity: 4.76\n",
      "Average loss at step 2500: 1.674261 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.28\n",
      "Validation set perplexity: 4.67\n",
      "Average loss at step 2600: 1.656662 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.62\n",
      "Validation set perplexity: 4.71\n",
      "Average loss at step 2700: 1.657320 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.56\n",
      "Validation set perplexity: 4.76\n",
      "Average loss at step 2800: 1.649632 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.66\n",
      "Validation set perplexity: 4.57\n",
      "Average loss at step 2900: 1.649268 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.72\n",
      "Validation set perplexity: 4.63\n",
      "Average loss at step 3000: 1.650288 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.06\n",
      "================================================================================\n",
      "on of who there and compudes the stall woble canto the mohomel languited about e\n",
      "ticles masts i aparthtom any trabbeth and was h searshin from the pamsipling in \n",
      "ticled to themened by paltical goving latony amainitral one nines and was port t\n",
      "dies counlorte io of treacan and their offout of the large long the connitist to\n",
      "er books as genallactor maptem the electionally or syapulty eve is includes to t\n",
      "================================================================================\n",
      "Validation set perplexity: 4.68\n",
      "Average loss at step 3100: 1.625020 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.81\n",
      "Validation set perplexity: 4.61\n",
      "Average loss at step 3200: 1.645323 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.53\n",
      "Validation set perplexity: 4.58\n",
      "Average loss at step 3300: 1.633804 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.93\n",
      "Validation set perplexity: 4.51\n",
      "Average loss at step 3400: 1.665682 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.53\n",
      "Validation set perplexity: 4.58\n",
      "Average loss at step 3500: 1.655936 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.40\n",
      "Validation set perplexity: 4.66\n",
      "Average loss at step 3600: 1.666588 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.55\n",
      "Validation set perplexity: 4.47\n",
      "Average loss at step 3700: 1.647831 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.12\n",
      "Validation set perplexity: 4.44\n",
      "Average loss at step 3800: 1.644732 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.57\n",
      "Validation set perplexity: 4.65\n",
      "Average loss at step 3900: 1.636704 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.15\n",
      "Validation set perplexity: 4.57\n",
      "Average loss at step 4000: 1.650686 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.70\n",
      "================================================================================\n",
      "tistice use enchosic clate  activity diregitations their viewis ancese adding pa\n",
      "rievide be the magri comped comptiste it germana with have ing in one zero zero \n",
      "junguelike order the comems mank citition artairs of an empored elaconts vore co\n",
      "x and is the same donea oke its seell playwide roope repeation deveter the story\n",
      "more feitioys aradtion averation of beinik easticiaters lani bealphess genes bel\n",
      "================================================================================\n",
      "Validation set perplexity: 4.57\n",
      "Average loss at step 4100: 1.626828 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.21\n",
      "Validation set perplexity: 4.60\n",
      "Average loss at step 4200: 1.634609 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.13\n",
      "Validation set perplexity: 4.50\n",
      "Average loss at step 4300: 1.614238 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.86\n",
      "Validation set perplexity: 4.46\n",
      "Average loss at step 4400: 1.606738 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.87\n",
      "Validation set perplexity: 4.42\n",
      "Average loss at step 4500: 1.612129 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.21\n",
      "Validation set perplexity: 4.59\n",
      "Average loss at step 4600: 1.609928 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.89\n",
      "Validation set perplexity: 4.74\n",
      "Average loss at step 4700: 1.620891 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.38\n",
      "Validation set perplexity: 4.53\n",
      "Average loss at step 4800: 1.627556 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.44\n",
      "Validation set perplexity: 4.46\n",
      "Average loss at step 4900: 1.628386 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.24\n",
      "Validation set perplexity: 4.54\n",
      "Average loss at step 5000: 1.608112 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.53\n",
      "================================================================================\n",
      "lem othericient love pradeo jaze criexitia the one nine four stantivuma one eigh\n",
      "ming the sacal mider to destrected a cameration writer carmique aff domegra one \n",
      "rityly the british practer four his pokhopland be jarg smm gamers off essemonder\n",
      "sted gasscors into the istable eax soriale per contemple tike of josusers hocgen\n",
      "venle game above trakies of ganmine from the five six zero zero yamatodd in are \n",
      "================================================================================\n",
      "Validation set perplexity: 4.46\n",
      "Average loss at step 5100: 1.605152 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.08\n",
      "Validation set perplexity: 4.36\n",
      "Average loss at step 5200: 1.585902 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.59\n",
      "Validation set perplexity: 4.27\n",
      "Average loss at step 5300: 1.574005 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.73\n",
      "Validation set perplexity: 4.26\n",
      "Average loss at step 5400: 1.578961 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.04\n",
      "Validation set perplexity: 4.26\n",
      "Average loss at step 5500: 1.562074 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.97\n",
      "Validation set perplexity: 4.22\n",
      "Average loss at step 5600: 1.579138 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.81\n",
      "Validation set perplexity: 4.22\n",
      "Average loss at step 5700: 1.565925 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.37\n",
      "Validation set perplexity: 4.22\n",
      "Average loss at step 5800: 1.577977 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.90\n",
      "Validation set perplexity: 4.22\n",
      "Average loss at step 5900: 1.571887 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.13\n",
      "Validation set perplexity: 4.24\n",
      "Average loss at step 6000: 1.543979 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.95\n",
      "================================================================================\n",
      "ationar reficuate computer perial observer in indic upper home of many in bill t\n",
      "ore world wishee lince rught that these in princulty a st kessociple ppooned to \n",
      "ver such againing the appecolly touron approper in titlance vinonfar what time t\n",
      "ur saighonese and matica i one nine shrroman has the was nationally bing some s \n",
      "y incognivectes with former s referving the sucoponed a particulty there issuing\n",
      "================================================================================\n",
      "Validation set perplexity: 4.22\n",
      "Average loss at step 6100: 1.565950 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.30\n",
      "Validation set perplexity: 4.19\n",
      "Average loss at step 6200: 1.535363 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.62\n",
      "Validation set perplexity: 4.18\n",
      "Average loss at step 6300: 1.544473 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.27\n",
      "Validation set perplexity: 4.18\n",
      "Average loss at step 6400: 1.539379 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.46\n",
      "Validation set perplexity: 4.16\n",
      "Average loss at step 6500: 1.558460 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.73\n",
      "Validation set perplexity: 4.16\n",
      "Average loss at step 6600: 1.594786 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.79\n",
      "Validation set perplexity: 4.15\n",
      "Average loss at step 6700: 1.577635 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.26\n",
      "Validation set perplexity: 4.17\n",
      "Average loss at step 6800: 1.606609 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.68\n",
      "Validation set perplexity: 4.18\n",
      "Average loss at step 6900: 1.581357 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.71\n",
      "Validation set perplexity: 4.18\n",
      "Average loss at step 7000: 1.578908 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.09\n",
      "================================================================================\n",
      "zers world the logragration notelomies headevils a stitotive killed accuring con\n",
      "x quiting varieation of this over times of germanistries that doebalm for the li\n",
      "g planims line by praces of burk was ang that troet relationary canyple ears by \n",
      "mated for the benow of empire goung dreents for devected has secondences go ub n\n",
      "hands at but the c three often five is a sachelated or neliad on his af was six \n",
      "================================================================================\n",
      "Validation set perplexity: 4.15\n"
     ]
    }
   ],
   "source": [
    "num_steps = 7001\n",
    "summary_frequency = 100\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  mean_loss = 0\n",
    "  for step in range(num_steps):\n",
    "    batches = train_batches.next()\n",
    "    feed_dict = dict()\n",
    "    for i in range(num_unrollings + 1):\n",
    "      feed_dict[train_data[i]] = batches[i]\n",
    "    _, l, predictions, lr = session.run(\n",
    "      [optimizer, loss, train_prediction, learning_rate], feed_dict=feed_dict)\n",
    "    mean_loss += l\n",
    "    if step % summary_frequency == 0:\n",
    "      if step > 0:\n",
    "        mean_loss = mean_loss / summary_frequency\n",
    "      # The mean loss is an estimate of the loss over the last few batches.\n",
    "      print(\n",
    "        'Average loss at step %d: %f learning rate: %f' % (step, mean_loss, lr))\n",
    "      mean_loss = 0\n",
    "      labels = np.concatenate(list(batches)[1:])\n",
    "      print('Minibatch perplexity: %.2f' % float(\n",
    "        np.exp(logprob(predictions, labels))))\n",
    "      if step % (summary_frequency * 10) == 0:\n",
    "        # Generate some samples.\n",
    "        print('=' * 80)\n",
    "        for _ in range(5):\n",
    "          feed = sample(random_distribution())\n",
    "          sentence = characters(feed)[0]\n",
    "          reset_sample_state.run()\n",
    "          for _ in range(79):\n",
    "            prediction = sample_prediction.eval({sample_input: feed})\n",
    "            feed = sample(prediction)\n",
    "            sentence += characters(feed)[0]\n",
    "          print(sentence)\n",
    "        print('=' * 80)\n",
    "      # Measure validation set perplexity.\n",
    "      reset_sample_state.run()\n",
    "      valid_logprob = 0\n",
    "      for _ in range(valid_size):\n",
    "        b = valid_batches.next()\n",
    "        predictions = sample_prediction.eval({sample_input: b[0]})\n",
    "        valid_logprob = valid_logprob + logprob(predictions, b[1])\n",
    "      print('Validation set perplexity: %.2f' % float(np.exp(\n",
    "        valid_logprob / valid_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pl4vtmFfa5nn"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "You might have noticed that the definition of the LSTM cell involves 4 matrix multiplications with the input, and 4 matrix multiplications with the output. Simplify the expression by using a single matrix multiply for each, and variables that are 4 times larger.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#num_nodes = 64\n",
    "num_nodes=256\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  \n",
    "  # Parameters:\n",
    "  # Input Multiply\n",
    "  X = tf.Variable(tf.truncated_normal([vocabulary_size,num_nodes*4],-0.1,0.1))\n",
    "  # Output Multiply\n",
    "  M = tf.Variable(tf.truncated_normal([num_nodes,num_nodes*4],-0.1,0.1))\n",
    "    \n",
    "  # Input gate: input, previous output, and bias.\n",
    "  ib = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Forget gate: input, previous output, and bias.\n",
    "  fb = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Memory cell: input, state and bias.                             \n",
    "  cb = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Output gate: input, previous output, and bias.\n",
    "  ob = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Variables saving state across unrollings.\n",
    "  saved_output = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "  saved_state = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "  # Classifier weights and biases.\n",
    "  w = tf.Variable(tf.truncated_normal([num_nodes, vocabulary_size], -0.1, 0.1))\n",
    "  b = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "  \n",
    "  # Definition of the cell computation.\n",
    "  def lstm_cell(i, o, state):\n",
    "    \"\"\"Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n",
    "    Note that in this formulation, we omit the various connections between the\n",
    "    previous state and the gates.\"\"\"\n",
    "    input_mult = tf.matmul(i,X)\n",
    "    output_mult = tf.matmul(o,M)\n",
    "    \n",
    "    input_gate = tf.sigmoid(input_mult[:,:num_nodes] + output_mult[:,:num_nodes] + ib)\n",
    "    forget_gate = tf.sigmoid(input_mult[:,num_nodes:2*num_nodes] + output_mult[:,num_nodes:2*num_nodes]+ fb)\n",
    "    update = input_mult[:,2*num_nodes:3*num_nodes] + output_mult[:,2*num_nodes:3*num_nodes] + cb\n",
    "    state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "    output_gate = tf.sigmoid(input_mult[:,3*num_nodes:4*num_nodes] + output_mult[:,3*num_nodes:4*num_nodes] + ob)\n",
    "    return output_gate * tf.tanh(state), state\n",
    "    \n",
    "\n",
    "  # Input data.\n",
    "  train_data = list()\n",
    "  for _ in range(num_unrollings + 1):\n",
    "    train_data.append(\n",
    "      tf.placeholder(tf.float32, shape=[batch_size,vocabulary_size]))\n",
    "  train_inputs = train_data[:num_unrollings]\n",
    "  train_labels = train_data[1:]  # labels are inputs shifted by one time step.\n",
    "\n",
    "  # Unrolled LSTM loop.\n",
    "  outputs = list()\n",
    "  output = saved_output\n",
    "  state = saved_state\n",
    "  for i in train_inputs:\n",
    "    output, state = lstm_cell(i, output, state)\n",
    "    outputs.append(output)\n",
    "\n",
    "  # State saving across unrollings.\n",
    "  with tf.control_dependencies([saved_output.assign(output),\n",
    "                                saved_state.assign(state)]):\n",
    "    # Classifier.\n",
    "    logits = tf.nn.xw_plus_b(tf.concat(0, outputs), w, b) #takes logits across entire batch\n",
    "    loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits, tf.concat(0, train_labels)))\n",
    "\n",
    "  # Optimizer.\n",
    "  global_step = tf.Variable(0)\n",
    "  learning_rate = tf.train.exponential_decay(\n",
    "    10.0, global_step, 10000, 0.1, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "  gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "  gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "  optimizer = optimizer.apply_gradients(\n",
    "    zip(gradients, v), global_step=global_step)\n",
    "\n",
    "  # Predictions.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  \n",
    "  # Sampling and validation eval: batch 1, no unrolling.\n",
    "  sample_input = tf.placeholder(tf.float32, shape=[1, vocabulary_size])\n",
    "  saved_sample_output = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  saved_sample_state = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  reset_sample_state = tf.group(\n",
    "    saved_sample_output.assign(tf.zeros([1, num_nodes])),\n",
    "    saved_sample_state.assign(tf.zeros([1, num_nodes])))\n",
    "  sample_output, sample_state = lstm_cell(\n",
    "    sample_input, saved_sample_output, saved_sample_state)\n",
    "  with tf.control_dependencies([saved_sample_output.assign(sample_output),\n",
    "                                saved_sample_state.assign(sample_state)]):\n",
    "    sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-a8e49ae89d07>:6 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Average loss at step 0: 3.318351 learning rate: 10.000000\n",
      "Minibatch perplexity: 27.61\n",
      "================================================================================\n",
      "hp sx scvv je che  agj oz paruy ii voamp octjwxxueistck dos hanynut atlnbfstx d |\n",
      "fycibpzast eznzpn cu jzr s  n csjaw  tagdifxnao egata  i  n  kieba i rbrlt rn xc|\n",
      "kz st t  ohdrar wamaedg pu ldycm wvvoc xh ru ii ey dy ti ta qg eithricdkhu s  ir|\n",
      "e nio f g  ew  it  dtin gygys vagip  j py ir oncjttvi ue  x qvalcedurd  wogts ok|\n",
      "vq r  asn o  me khth xlsti erzuhe e gv hysra p  ta  awbnaplegdte  ix tf rh nt yg|\n",
      "================================================================================\n",
      "Validation set perplexity: 22.18\n",
      "Average loss at step 100: 2.930321 learning rate: 10.000000\n",
      "Minibatch perplexity: 14.28\n",
      "Validation set perplexity: 13.86\n",
      "Average loss at step 200: 2.521372 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.21\n",
      "Validation set perplexity: 11.63\n",
      "Average loss at step 300: 2.297212 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.66\n",
      "Validation set perplexity: 9.77\n",
      "Average loss at step 400: 2.183608 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.51\n",
      "Validation set perplexity: 9.02\n",
      "Average loss at step 500: 2.112771 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.49\n",
      "Validation set perplexity: 8.30\n",
      "Average loss at step 600: 2.049283 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.05\n",
      "Validation set perplexity: 7.75\n",
      "Average loss at step 700: 2.018306 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.71\n",
      "Validation set perplexity: 7.53\n",
      "Average loss at step 800: 1.975511 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.34\n",
      "Validation set perplexity: 7.32\n",
      "Average loss at step 900: 1.946875 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.96\n",
      "Validation set perplexity: 6.99\n",
      "Average loss at step 1000: 1.912259 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.20\n",
      "================================================================================\n",
      "es seasere fovey boba pressed in blilupphe toonstent and secentian withen adotua|\n",
      "gew to compenter withan efgerailed afdee betheen zere eight conling worly aries |\n",
      "modesed whock peea zeloss pooyobranissameved than tradicance ovey forned for asa|\n",
      " min then throok capomalles fhrem baster in peomensed goodues of the recenivisti|\n",
      "uelter of adic glesew wosteds in one flated ypountery besements by wad zester th|\n",
      "================================================================================\n",
      "Validation set perplexity: 6.90\n",
      "Average loss at step 1100: 1.888498 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.61\n",
      "Validation set perplexity: 6.54\n",
      "Average loss at step 1200: 1.847612 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.15\n",
      "Validation set perplexity: 6.49\n",
      "Average loss at step 1300: 1.873689 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.43\n",
      "Validation set perplexity: 6.14\n",
      "Average loss at step 1400: 1.830470 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.44\n",
      "Validation set perplexity: 6.23\n",
      "Average loss at step 1500: 1.800545 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.56\n",
      "Validation set perplexity: 5.83\n",
      "Average loss at step 1600: 1.779853 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.90\n",
      "Validation set perplexity: 6.03\n",
      "Average loss at step 1700: 1.743959 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.13\n",
      "Validation set perplexity: 5.71\n",
      "Average loss at step 1800: 1.727912 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.12\n",
      "Validation set perplexity: 5.65\n",
      "Average loss at step 1900: 1.707915 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.75\n",
      "Validation set perplexity: 5.44\n",
      "Average loss at step 2000: 1.706111 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.45\n",
      "================================================================================\n",
      "eritas esaxuble sicheen includin and was wored oy dised vave mistiolout maranume|\n",
      "ctus of  araby with evenlent and thas incapodiem of the boelograge monempome in |\n",
      "nersuan studs a groples asseatity doit disament side soum a glen tfos of many of|\n",
      "forces film not boots greeney hallar to are used yauthry luver aypo points the g|\n",
      "e of euth shoptd and conjunlibl mogn thours of the actory owe seven four used sy|\n",
      "================================================================================\n",
      "Validation set perplexity: 5.59\n",
      "Average loss at step 2100: 1.678927 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.24\n",
      "Validation set perplexity: 5.36\n",
      "Average loss at step 2200: 1.678195 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.87\n",
      "Validation set perplexity: 5.42\n",
      "Average loss at step 2300: 1.639639 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.85\n",
      "Validation set perplexity: 5.18\n",
      "Average loss at step 2400: 1.641080 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.56\n",
      "Validation set perplexity: 5.01\n",
      "Average loss at step 2500: 1.627804 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.65\n",
      "Validation set perplexity: 4.89\n",
      "Average loss at step 2600: 1.637881 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.21\n",
      "Validation set perplexity: 4.97\n",
      "Average loss at step 2700: 1.632725 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.00\n",
      "Validation set perplexity: 4.80\n",
      "Average loss at step 2800: 1.621685 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.96\n",
      "Validation set perplexity: 4.78\n",
      "Average loss at step 2900: 1.582405 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.96\n",
      "Validation set perplexity: 4.82\n",
      "Average loss at step 3000: 1.557312 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.32\n",
      "================================================================================\n",
      "hera stardly order franch pagabor party key be cour usershric southershdolity at|\n",
      "st by the pows is as a provabife the relations att chirest wouldwed ay the muser|\n",
      "mac counosuatorared a crease used sceen as kave if artistly actions band is was |\n",
      "wer for that as the santon lotter s clatan bouk when treation addectures wespeas|\n",
      "xaward spect eirates nul bother beov new of one nine seven seven two three fins |\n",
      "================================================================================\n",
      "Validation set perplexity: 4.56\n",
      "Average loss at step 3100: 1.563186 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.60\n",
      "Validation set perplexity: 4.54\n",
      "Average loss at step 3200: 1.547428 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.48\n",
      "Validation set perplexity: 4.63\n",
      "Average loss at step 3300: 1.550453 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.97\n",
      "Validation set perplexity: 4.63\n",
      "Average loss at step 3400: 1.551822 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.93\n",
      "Validation set perplexity: 4.58\n",
      "Average loss at step 3500: 1.542345 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.89\n",
      "Validation set perplexity: 4.57\n",
      "Average loss at step 3600: 1.533898 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.63\n",
      "Validation set perplexity: 4.44\n",
      "Average loss at step 3700: 1.563654 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.89\n",
      "Validation set perplexity: 4.42\n",
      "Average loss at step 3800: 1.533634 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.30\n",
      "Validation set perplexity: 4.42\n",
      "Average loss at step 3900: 1.540859 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.77\n",
      "Validation set perplexity: 4.42\n",
      "Average loss at step 4000: 1.538469 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.94\n",
      "================================================================================\n",
      "x new coke native dre used dath as five one eight three earolard citys and basic|\n",
      "ymina ochning oxammalan bights kohedium as for jernopon fens annourn whom coit s|\n",
      "gatic equivaling the lminked in sexies without himply the some hamradian ady for|\n",
      "t from phatabol dfctural altimiden fediline there prodinct but the fins one of w|\n",
      "zion piew d k one newsey however vpo and less this centralian after the and erch|\n",
      "================================================================================\n",
      "Validation set perplexity: 4.61\n",
      "Average loss at step 4100: 1.536809 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.62\n",
      "Validation set perplexity: 4.48\n",
      "Average loss at step 4200: 1.519904 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.54\n",
      "Validation set perplexity: 4.28\n",
      "Average loss at step 4300: 1.476229 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.60\n",
      "Validation set perplexity: 4.40\n",
      "Average loss at step 4400: 1.499756 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.04\n",
      "Validation set perplexity: 4.37\n",
      "Average loss at step 4500: 1.470751 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.49\n",
      "Validation set perplexity: 4.32\n",
      "Average loss at step 4600: 1.482473 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.61\n",
      "Validation set perplexity: 4.36\n",
      "Average loss at step 4700: 1.489324 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.83\n",
      "Validation set perplexity: 4.44\n",
      "Average loss at step 4800: 1.477901 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.47\n",
      "Validation set perplexity: 4.14\n",
      "Average loss at step 4900: 1.497445 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.13\n",
      "Validation set perplexity: 4.43\n",
      "Average loss at step 5000: 1.527756 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.72\n",
      "================================================================================\n",
      "ulate green htap interpector one nine seven and ceremis jonah with doct on his o|\n",
      "puls to bigm france porze logy a present success in the case of three electrical|\n",
      "one see a formmal an refacred by tainter of the norlou most aborthon ennoted thr|\n",
      "zin will conceil of the are john or example cases that the empses makestrate in |\n",
      "ub normastement developed by thought most philoss a wimes a homey in theirf one |\n",
      "================================================================================\n",
      "Validation set perplexity: 4.38\n",
      "Average loss at step 5100: 1.502806 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.71\n",
      "Validation set perplexity: 4.46\n",
      "Average loss at step 5200: 1.505052 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.13\n",
      "Validation set perplexity: 4.33\n",
      "Average loss at step 5300: 1.502730 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.20\n",
      "Validation set perplexity: 4.33\n",
      "Average loss at step 5400: 1.494196 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.22\n",
      "Validation set perplexity: 4.21\n",
      "Average loss at step 5500: 1.497758 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.36\n",
      "Validation set perplexity: 4.37\n",
      "Average loss at step 5600: 1.505882 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 4.25\n",
      "Average loss at step 5700: 1.479340 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.13\n",
      "Validation set perplexity: 4.25\n",
      "Average loss at step 5800: 1.492821 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.48\n",
      "Validation set perplexity: 4.38\n",
      "Average loss at step 5900: 1.465837 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.40\n",
      "Validation set perplexity: 4.44\n",
      "Average loss at step 6000: 1.490534 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.46\n",
      "================================================================================\n",
      "dagen protoned from one zero three eight borbord on the destrucing the poeu coun|\n",
      "m playost many s however to om silum from outcount its at unflenane monumental a|\n",
      "ing best they end o miny a lenglask war construction the only king on gata codas|\n",
      "prison or revisix hat the northernor f more to that the trauty to known the grea|\n",
      "ro s discussion exkelline ocloudings since one five zero five five seven after c|\n",
      "================================================================================\n",
      "Validation set perplexity: 4.47\n",
      "Average loss at step 6100: 1.490088 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.22\n",
      "Validation set perplexity: 4.39\n",
      "Average loss at step 6200: 1.462767 learning rate: 10.000000\n",
      "Minibatch perplexity: 3.89\n",
      "Validation set perplexity: 4.31\n",
      "Average loss at step 6300: 1.432471 learning rate: 10.000000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 4.43\n",
      "Average loss at step 6400: 1.431953 learning rate: 10.000000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 4.12\n",
      "Average loss at step 6500: 1.423304 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 4.12\n",
      "Average loss at step 6600: 1.435329 learning rate: 10.000000\n",
      "Minibatch perplexity: 3.94\n",
      "Validation set perplexity: 4.17\n",
      "Average loss at step 6700: 1.432981 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.10\n",
      "Validation set perplexity: 4.34\n",
      "Average loss at step 6800: 1.433041 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.13\n",
      "Validation set perplexity: 4.36\n",
      "Average loss at step 6900: 1.428445 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.91\n",
      "Validation set perplexity: 4.20\n",
      "Average loss at step 7000: 1.412856 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.17\n",
      "================================================================================\n",
      "inate airchal reakery airlinue did all novelly to arable food of food he was was|\n",
      "able cricing as a carlesean arcauded fyderal othosen have its quantir hasping hi|\n",
      "x are times wife in a team of foreign speivers anabybane seal successfrate s hav|\n",
      "unated and introllination taken anathereth century we hostes may incompany law s|\n",
      "rade officed camperigets of capar word of the davis the past and kapes seen earl|\n",
      "================================================================================\n",
      "Validation set perplexity: 4.07\n",
      "Average loss at step 7100: 1.390673 learning rate: 10.000000\n",
      "Minibatch perplexity: 3.62\n",
      "Validation set perplexity: 4.11\n",
      "Average loss at step 7200: 1.407206 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.20\n",
      "Validation set perplexity: 4.04\n",
      "Average loss at step 7300: 1.410432 learning rate: 10.000000\n",
      "Minibatch perplexity: 3.46\n",
      "Validation set perplexity: 4.20\n",
      "Average loss at step 7400: 1.402021 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.14\n",
      "Validation set perplexity: 4.33\n",
      "Average loss at step 7500: 1.426898 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.24\n",
      "Validation set perplexity: 4.42\n",
      "Average loss at step 7600: 1.426397 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.28\n",
      "Validation set perplexity: 4.24\n",
      "Average loss at step 7700: 1.413918 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.26\n",
      "Validation set perplexity: 4.21\n",
      "Average loss at step 7800: 1.380533 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.14\n",
      "Validation set perplexity: 4.03\n",
      "Average loss at step 7900: 1.403050 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.96\n",
      "Average loss at step 8000: 1.389190 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.20\n",
      "================================================================================\n",
      "ureicd in one nine two timet schemmanic gas on tabil a trial command relieintile|\n",
      "ful span it luggach burnensurg reantative that these city to flacinh american vo|\n",
      "mistery what had rrosen of the expressed knowly of methods to dots that turen ha|\n",
      "y rosal time to been book addlead aquiries repressed is may counter francist the|\n",
      "us urwar norge of brother was one nine six seven sidewi guatemboaps experiently |\n",
      "================================================================================\n",
      "Validation set perplexity: 4.10\n",
      "Average loss at step 8100: 1.390454 learning rate: 10.000000\n",
      "Minibatch perplexity: 3.96\n",
      "Validation set perplexity: 4.03\n",
      "Average loss at step 8200: 1.410481 learning rate: 10.000000\n",
      "Minibatch perplexity: 3.85\n",
      "Validation set perplexity: 3.92\n",
      "Average loss at step 8300: 1.409233 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.04\n",
      "Validation set perplexity: 4.00\n",
      "Average loss at step 8400: 1.413679 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.25\n",
      "Validation set perplexity: 4.21\n",
      "Average loss at step 8500: 1.386074 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.18\n",
      "Validation set perplexity: 4.00\n",
      "Average loss at step 8600: 1.402431 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.52\n",
      "Validation set perplexity: 3.88\n",
      "Average loss at step 8700: 1.414371 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.19\n",
      "Validation set perplexity: 4.09\n",
      "Average loss at step 8800: 1.404281 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.11\n",
      "Validation set perplexity: 4.11\n",
      "Average loss at step 8900: 1.399868 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.07\n",
      "Validation set perplexity: 4.05\n",
      "Average loss at step 9000: 1.390112 learning rate: 10.000000\n",
      "Minibatch perplexity: 3.72\n",
      "================================================================================\n",
      " philbip was not funtity of videny planke a made volract ofter confiderary of th|\n",
      "ten that the team go one percent marian sellowion five coles field fb gnabus her|\n",
      "ing proceduer treavhy glock sequentiniable in win amorgina gsr guaros b k one n |\n",
      "ver a hig one eight five famous one nine six chayists theoreply an insumented in|\n",
      "an s manyager s standard refuses of fort of the fort is s many falls the went th|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.99\n",
      "Average loss at step 9100: 1.397854 learning rate: 10.000000\n",
      "Minibatch perplexity: 3.76\n",
      "Validation set perplexity: 3.95\n",
      "Average loss at step 9200: 1.402459 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.78\n",
      "Validation set perplexity: 4.07\n",
      "Average loss at step 9300: 1.376070 learning rate: 10.000000\n",
      "Minibatch perplexity: 3.89\n",
      "Validation set perplexity: 4.05\n",
      "Average loss at step 9400: 1.386191 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 4.04\n",
      "Average loss at step 9500: 1.400964 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.73\n",
      "Validation set perplexity: 4.06\n",
      "Average loss at step 9600: 1.368911 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.59\n",
      "Validation set perplexity: 3.97\n",
      "Average loss at step 9700: 1.403587 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.98\n",
      "Average loss at step 9800: 1.402240 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 4.07\n",
      "Average loss at step 9900: 1.413234 learning rate: 10.000000\n",
      "Minibatch perplexity: 3.83\n",
      "Validation set perplexity: 4.17\n",
      "Average loss at step 10000: 1.440823 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.89\n",
      "================================================================================\n",
      "zign gichter upilly and modern are to the ultimatable on acroded from dribeliest|\n",
      "e important a high casually in the saints using biast as will instance of skaleb|\n",
      "ff biespriefifie trouply aken ibn congignson mus euvasurities are amount an exta|\n",
      "nt lost description is also well as eather referring the c total governor of int|\n",
      "dlat bleck from united this are areas about biscops texas some are had than phir|\n",
      "================================================================================\n",
      "Validation set perplexity: 4.02\n",
      "Average loss at step 10100: 1.410066 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.76\n",
      "Validation set perplexity: 3.89\n",
      "Average loss at step 10200: 1.373853 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.64\n",
      "Validation set perplexity: 3.89\n",
      "Average loss at step 10300: 1.375235 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.56\n",
      "Validation set perplexity: 3.85\n",
      "Average loss at step 10400: 1.387772 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.58\n",
      "Validation set perplexity: 3.86\n",
      "Average loss at step 10500: 1.380453 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.89\n",
      "Validation set perplexity: 3.83\n",
      "Average loss at step 10600: 1.372438 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.09\n",
      "Validation set perplexity: 3.82\n",
      "Average loss at step 10700: 1.387442 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.90\n",
      "Validation set perplexity: 3.82\n",
      "Average loss at step 10800: 1.386390 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.65\n",
      "Validation set perplexity: 3.77\n",
      "Average loss at step 10900: 1.394185 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.28\n",
      "Validation set perplexity: 3.73\n",
      "Average loss at step 11000: 1.396051 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.13\n",
      "================================================================================\n",
      "xing is artist one six eight three two histor of best or a seven two angent gree|\n",
      "ant between then abscremes for then the republic of f p egnstage entry four zequ|\n",
      "magher was both in a died your artist from users marie  and method lant bernashi|\n",
      "der chard of per war divisions is supposes are science the clysox pp language el|\n",
      "quity what decent europe in itilised certain between enterpube not critices enge|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.72\n",
      "Average loss at step 11100: 1.371918 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 3.71\n",
      "Average loss at step 11200: 1.403094 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.81\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 11300: 1.392687 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.13\n",
      "Validation set perplexity: 3.73\n",
      "Average loss at step 11400: 1.384619 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.29\n",
      "Validation set perplexity: 3.71\n",
      "Average loss at step 11500: 1.393186 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.81\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 11600: 1.416798 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.72\n",
      "Average loss at step 11700: 1.385637 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.71\n",
      "Average loss at step 11800: 1.384787 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.44\n",
      "Validation set perplexity: 3.72\n",
      "Average loss at step 11900: 1.365933 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.70\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 12000: 1.377375 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.64\n",
      "================================================================================\n",
      "pted in hearson com rise oy united states from any along the australia and indus|\n",
      "re acts wilsols land warse social burddlan free softwork he see replaced wniking|\n",
      "y three in laksby secret find and the memory of other sometimes unitarians acyul|\n",
      " east basidition one zero two gs the deaths one nine th century and others engli|\n",
      "beric trnates the transportation units opposite pound are any organization to th|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 12100: 1.402996 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.71\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 12200: 1.410705 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.88\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 12300: 1.395698 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.24\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 12400: 1.389770 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.25\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 12500: 1.380718 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.15\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 12600: 1.370853 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.95\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 12700: 1.372853 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.87\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 12800: 1.392626 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.07\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 12900: 1.395941 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.98\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 13000: 1.383515 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.67\n",
      "================================================================================\n",
      "nity echansulvy durses phossioks in the give givetri the ground rejustificance t|\n",
      "ulal morian generally mnoting the prologing with south african gv velrida s holl|\n",
      "va is a plants not heidell about recomsensed writ and human level limities from |\n",
      "t besch a recent maller guiding and increasing fe dints most history of immedted|\n",
      "t surpscities the national his hes shf forced by end obity of retrotest the coun|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 13100: 1.382779 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.18\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 13200: 1.397821 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.42\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 13300: 1.392283 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.03\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 13400: 1.368116 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.72\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 13500: 1.368419 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.74\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 13600: 1.395276 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.70\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 13700: 1.373043 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.14\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 13800: 1.377531 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.73\n",
      "Validation set perplexity: 3.61\n",
      "Average loss at step 13900: 1.397145 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 14000: 1.391753 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.09\n",
      "================================================================================\n",
      "jace to briish thepes economy and copper for eti matt for facification personal |\n",
      "queing the poinced have december two paint the inst tripled with foown whether e|\n",
      "ns the like order to reemonable trust related in break he western seniol shot br|\n",
      "xidae a species harrieg klowed to believed to eatine the greeten in it to hizsin|\n",
      "jer economic called christial department of the wlunt in north charatobsoy speak|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 14100: 1.385611 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.79\n",
      "Validation set perplexity: 3.62\n",
      "Average loss at step 14200: 1.395804 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.48\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 14300: 1.396199 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.08\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 14400: 1.374813 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 14500: 1.393643 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.85\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 14600: 1.369452 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.98\n",
      "Validation set perplexity: 3.62\n",
      "Average loss at step 14700: 1.364723 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.26\n",
      "Validation set perplexity: 3.62\n",
      "Average loss at step 14800: 1.349531 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.15\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 14900: 1.374689 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.04\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 15000: 1.364512 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.16\n",
      "================================================================================\n",
      "wood four four zero youthnazel is a troops two third town and ca public of repla|\n",
      "z mama brown but pattannex barvalan short directly above a four new gobles by th|\n",
      "zyze a judaha emct of the smbker aregless relolider and justot of film the time |\n",
      "yla b havour two soldress and wishing wheree such as identified the rapi mediaqu|\n",
      "es of the plassing marcus judaism computer place in state federated harmy use in|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 15100: 1.355863 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.64\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 15200: 1.371701 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.84\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 15300: 1.385700 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 15400: 1.372855 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.21\n",
      "Validation set perplexity: 3.62\n",
      "Average loss at step 15500: 1.363805 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.81\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 15600: 1.356647 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 15700: 1.398761 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 15800: 1.393506 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.60\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 15900: 1.385111 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 16000: 1.383387 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.74\n",
      "================================================================================\n",
      "ana body damagus travition is a loradous transfers is key the handlest gp ba tak|\n",
      "ruatine without tried music usu explicitial in television of software to human m|\n",
      "ked ruck sectors two zero zero five two three th and two zero zero five kilicard|\n",
      "onian and the dons sorboungl esclin his disprovedby the crash not for mode the m|\n",
      " and the united several artists hlayaroy vs reprevaled that less that human and |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 16100: 1.386107 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.39\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 16200: 1.363052 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 16300: 1.376693 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 16400: 1.360106 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.59\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 16500: 1.403855 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.08\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 16600: 1.362556 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.37\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 16700: 1.387898 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.86\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 16800: 1.395450 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.91\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 16900: 1.355526 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.10\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 17000: 1.373566 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.86\n",
      "================================================================================\n",
      "ning viagenia main anythers equal to expressed his romania considernt the westin|\n",
      "hannar result bebrilding dicting elected to at western estaphia economy list bec|\n",
      "ctisguin earl was treature for the unixgelity mondonise in the so both on the so|\n",
      "y in one six one nine zero von of gillin bane at the stago of the w sypar adult |\n",
      "ne evane dazger callarn filing suectuate types was fact depending to after beays|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 17100: 1.359390 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.16\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 17200: 1.393121 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 17300: 1.387369 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 17400: 1.370449 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.66\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 17500: 1.380130 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.34\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 17600: 1.376292 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.90\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 17700: 1.404564 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 17800: 1.364183 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.84\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 17900: 1.353326 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 18000: 1.361489 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.80\n",
      "================================================================================\n",
      "vatical amostical during htarding compreherably used in them model was by groupt|\n",
      "a frey drive the concerned underwall synthesis very court for the make generical|\n",
      "ficictex force lines of italize iis great has have songs dno n then sdifted to b|\n",
      "rationadil for example of aditifatures ultiman watership the dishoidstorie fugen|\n",
      "ge the maltyroundiuk often defense at long musicia information of the first usea|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 18100: 1.367209 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.85\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 18200: 1.360611 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.75\n",
      "Validation set perplexity: 3.71\n",
      "Average loss at step 18300: 1.337323 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.75\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 18400: 1.355783 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 18500: 1.319389 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.46\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 18600: 1.311238 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 18700: 1.343106 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.52\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 18800: 1.377011 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.18\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 18900: 1.363753 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.71\n",
      "Average loss at step 19000: 1.394958 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.78\n",
      "================================================================================\n",
      "que nettering mmucitages other meat s six greek as inderwesses a king condectari|\n",
      "or beban sibling idea five terre six to for a cline embetierchicallan informatio|\n",
      "ger he roll they has cape rober tribely in fundamental revolumental drogict fact|\n",
      "t timis in between deaths its mission or responsible a genestine although icopen|\n",
      "reside clarkney after for movement of one the mercine fame perhaps one nine a fr|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.72\n",
      "Average loss at step 19100: 1.355273 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.59\n",
      "Validation set perplexity: 3.71\n",
      "Average loss at step 19200: 1.368100 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.82\n",
      "Validation set perplexity: 3.72\n",
      "Average loss at step 19300: 1.320852 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.71\n",
      "Average loss at step 19400: 1.370418 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.57\n",
      "Validation set perplexity: 3.71\n",
      "Average loss at step 19500: 1.344892 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.13\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 19600: 1.350880 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.70\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 19700: 1.345510 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.66\n",
      "Validation set perplexity: 3.70\n",
      "Average loss at step 19800: 1.346880 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.36\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 19900: 1.344815 learning rate: 1.000000\n",
      "Minibatch perplexity: 3.90\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 20000: 1.365384 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.93\n",
      "================================================================================\n",
      "vard the life the baromarus s tankings fibratively abbentions explored independe|\n",
      "jer play muesical god boll madnet acyremospall imprises a pregien to kark tillia|\n",
      "west mexhama bliending themselves undeveral deathant in way or namo coast on the|\n",
      "s are ethnic communitae by moral votlation of londonning called in other curk th|\n",
      "ch of amstadi paland ng it express von beyond fijhtements although that they hyp|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 20100: 1.347186 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.62\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 20200: 1.356973 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.89\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 20300: 1.357066 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.26\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 20400: 1.343173 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.87\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 20500: 1.390426 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 20600: 1.366320 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.78\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 20700: 1.372632 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.70\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 20800: 1.359963 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.13\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 20900: 1.357755 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.90\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 21000: 1.366311 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.64\n",
      "================================================================================\n",
      "el isinely predicting a machineas cost user such after the ending very magazine |\n",
      "vo they in the greno muslim back of intended interest given on drecm buflean fas|\n",
      "le a sufferable main beauting to wind corporals oxyition considered in one nine |\n",
      "m sale chairman auteds ida in the net vike book for an entirely that they cape a|\n",
      "ley jathle is its known underwowning species including the different sin bluebau|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 21100: 1.381103 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 21200: 1.410196 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.77\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 21300: 1.401597 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.72\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 21400: 1.405580 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.38\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 21500: 1.396559 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.41\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 21600: 1.396403 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.69\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 21700: 1.417723 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.22\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 21800: 1.427365 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.19\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 21900: 1.385416 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.85\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 22000: 1.377204 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.66\n",
      "================================================================================\n",
      "it independence and the latzu there was exalt million more regularly most forum |\n",
      "y hand from which tried hearn setricial marbys is religious poup securities elos|\n",
      "ware belzium and the ages to mesming volmenha tankelin penf and at a scotlanding|\n",
      "pers and or the essia the school imported anda manitosabo animationary execution|\n",
      "ge clints is visirs at the firity in one nine eight nine two six zero seven five|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 22100: 1.403653 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 22200: 1.391043 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.18\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 22300: 1.397377 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.78\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 22400: 1.392315 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.94\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 22500: 1.403799 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 22600: 1.401462 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.22\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 22700: 1.416362 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.22\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 22800: 1.370692 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.47\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 22900: 1.378330 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.29\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 23000: 1.402610 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.74\n",
      "================================================================================\n",
      "net museum and lund or emamplibrion outsurrent batmoned buf thought base ticket |\n",
      "xied were multipas guinan we days yarxan unixia critics question of his orthodox|\n",
      "dessolia abratheos a notal this at the existencials universities and toon what w|\n",
      "y are read newly laten metric and middly and trade marriage analased gnossidies |\n",
      "u met law travels and offered with gonn potre waden bras and as a real developme|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 23100: 1.381831 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.25\n",
      "Validation set perplexity: 3.69\n",
      "Average loss at step 23200: 1.363087 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.41\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 23300: 1.388111 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.75\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 23400: 1.385486 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.51\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 23500: 1.368896 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.70\n",
      "Validation set perplexity: 3.68\n",
      "Average loss at step 23600: 1.354980 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.61\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 23700: 1.381545 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.62\n",
      "Validation set perplexity: 3.67\n",
      "Average loss at step 23800: 1.376048 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.74\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 23900: 1.360390 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 24000: 1.363124 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.06\n",
      "================================================================================\n",
      "men was to the open dpals had is amount baw brop enough decided to movomets in e|\n",
      "m liberal votations on the disport of fashions that any three seven one one thre|\n",
      "y germany that is democrats by adjust the friends followed for the short said pr|\n",
      "pi time which serman periles there were eonsed chemical overset in being to the |\n",
      "wand with easery or edecuries hammot and mexico subject in the three one nine fi|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 24100: 1.387080 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.58\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 24200: 1.387415 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 24300: 1.390170 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.51\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 24400: 1.404471 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.39\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 24500: 1.387253 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.82\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 24600: 1.356614 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.66\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 24700: 1.357719 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 24800: 1.369917 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.86\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 24900: 1.395410 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.07\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 25000: 1.397096 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.34\n",
      "================================================================================\n",
      "omable close of est exile card he case at bits was consciousnestic control to in|\n",
      "a one nine five birnion equilonger one eight girr into a circle was army sahars |\n",
      "kings where uk increa when subject the behaviorholdremat in the under to connect|\n",
      "s which have anought other channel by make to the film obserce and although hit |\n",
      "kic ailsone and logic he is with phulkiash informatily of orian kind political f|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 25100: 1.380349 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.53\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 25200: 1.373115 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.81\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 25300: 1.409634 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 25400: 1.382724 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.85\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 25500: 1.363870 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 25600: 1.360518 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.93\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 25700: 1.380079 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.14\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 25800: 1.415341 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.40\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 25900: 1.369646 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.52\n",
      "Validation set perplexity: 3.62\n",
      "Average loss at step 26000: 1.395585 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.30\n",
      "================================================================================\n",
      "taborg the odnawoic writing work where they are on the about the network part of|\n",
      "on perrowsllum international member though many metrogless circu computtion usin|\n",
      "cesia king of his mineraciles as teach it was soviet and use of has again stone |\n",
      "el piter brunstlum factes letters of allows canadian sinners genes man easwi rea|\n",
      "dresy own composering to medicine both from murgically equalities in the person |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 26100: 1.400390 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.56\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 26200: 1.392281 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.24\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 26300: 1.366853 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.04\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 26400: 1.401410 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.93\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 26500: 1.366690 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.75\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 26600: 1.371414 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 26700: 1.361248 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.83\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 26800: 1.373969 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.12\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 26900: 1.362190 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.05\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 27000: 1.375546 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.93\n",
      "================================================================================\n",
      "quesa most spent replyingem schools furtherman the nationalist de sand coup q no|\n",
      "urancy would be supplacred li straxaccov hands other operatin into over states w|\n",
      "x he well as not dell frac commercioral non ostelling is made a city from the do|\n",
      "uracicia tending samen a dajaid critical identity however the brascle pc lenesib|\n",
      "pitica by julk technical very presented it weapours are rooting gividge worked r|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 27100: 1.369882 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.46\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 27200: 1.388778 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.41\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 27300: 1.405592 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.21\n",
      "Validation set perplexity: 3.63\n",
      "Average loss at step 27400: 1.370477 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.89\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 27500: 1.349516 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.82\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 27600: 1.367938 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.93\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 27700: 1.389054 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.63\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 27800: 1.392781 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 27900: 1.385165 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.69\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 28000: 1.376793 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.06\n",
      "================================================================================\n",
      "x farce external links rather the fish balloov c for france are andwaded he bush|\n",
      "on one nine cuast aka attamination and east gate actors formations hatftcri four|\n",
      "zie a economic history is ware inairs core war office five eight zero small muld|\n",
      "n proction used in contract to other unlize proposed with world also seven horsi|\n",
      "hon the invosal aga s uppress gelevoing john latelle s one nine one six male eil|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 28100: 1.377548 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.81\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 28200: 1.350712 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.66\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 28300: 1.370123 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.93\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 28400: 1.350959 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 28500: 1.391462 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 28600: 1.400244 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.05\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 28700: 1.365115 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.78\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 28800: 1.380556 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.52\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 28900: 1.380483 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.59\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 29000: 1.360733 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.67\n",
      "================================================================================\n",
      "devered hreet laan bayksan eugenez and the protecting that five five four inform|\n",
      "nator supporter two nine five one five and rewended to four ctile convention jed|\n",
      "berchfle as waternal and send the first is a tradition of chamilrong burea thoug|\n",
      "linoree declarations novel gun tributus royal qree guits halling ruler itale gra|\n",
      "ph algorithms matters to ausa a s election for nov space was boyl one three one |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 29100: 1.347808 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.41\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 29200: 1.368274 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 29300: 1.425787 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.16\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 29400: 1.356681 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.10\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 29500: 1.413101 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.54\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 29600: 1.376248 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.16\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 29700: 1.380351 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.73\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 29800: 1.373635 learning rate: 0.100000\n",
      "Minibatch perplexity: 3.95\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 29900: 1.366446 learning rate: 0.100000\n",
      "Minibatch perplexity: 4.15\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 30000: 1.366281 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.63\n",
      "================================================================================\n",
      "ffering charches of campoillogy in callions called arlin particular hald about o|\n",
      "jerd one world carladed oij just correction by the one nine nine five zero batte|\n",
      "ment minorian apolde and consultant those has the sourcess newsone luthue forler|\n",
      "l labour diddin covered to prohing with the wera successful july in city along w|\n",
      "ches and example to continued music blood growth at spanish holi their poet song|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 30100: 1.372531 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.16\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 30200: 1.386283 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.26\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 30300: 1.392934 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.22\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 30400: 1.383893 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.96\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 30500: 1.389651 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.36\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 30600: 1.372076 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.43\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 30700: 1.366871 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 30800: 1.403595 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 30900: 1.401211 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.11\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 31000: 1.377735 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.50\n",
      "================================================================================\n",
      "fran and and besoftermus successful ecomogries of bemon pronoungly eseantel in p|\n",
      "i the area actinestrina corporated boukged and his four zero zatural control of |\n",
      "we wealth determined states on of the xpreves region beyond on the condite the c|\n",
      "men or funday eagli a strabilit taboom naso going in one zero zero zero zero eig|\n",
      "bir sourcer excluded are thishiest was team home period year frequently and less|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 31100: 1.396975 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.51\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 31200: 1.386846 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.63\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 31300: 1.390731 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 31400: 1.356298 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.82\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 31500: 1.349638 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.12\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 31600: 1.394024 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.11\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 31700: 1.372104 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.98\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 31800: 1.373572 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.11\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 31900: 1.370130 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.17\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 32000: 1.383880 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.72\n",
      "================================================================================\n",
      "gan is also also an established by who list of c racing b one nine seven zero s |\n",
      "ors nature the eutholese from the theory of last alosts to born to the far or la|\n",
      "ve were means from useres of the synothest called first ewhern padelecan autabic|\n",
      "ftard from the curied is marryackarkwams protoux bego expression coems to comple|\n",
      "words when to be in foretry one four five one seven zero one electrical cignarld|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 32100: 1.371093 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.73\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 32200: 1.390374 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 32300: 1.398984 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.59\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 32400: 1.371464 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 32500: 1.380316 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.43\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 32600: 1.375109 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.12\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 32700: 1.380875 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.33\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 32800: 1.387994 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.31\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 32900: 1.380895 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.18\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 33000: 1.387357 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.96\n",
      "================================================================================\n",
      "rich s s regulation of wildeads many of one was through woos andwassate and mona|\n",
      "f turk from one one zero zero s the consequence performanced on provides face el|\n",
      "za fize french pricitpolar cases model due to dientley the foeling leganing extr|\n",
      "ville marketial his literature etsymity in the term if as a buri problem with ex|\n",
      "bood slyphon four century finmating in history of guest development actlases pre|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 33100: 1.369895 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.21\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 33200: 1.375297 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.91\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 33300: 1.359788 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.81\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 33400: 1.358094 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.67\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 33500: 1.395386 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.67\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 33600: 1.367676 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 33700: 1.417523 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.41\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 33800: 1.363788 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.85\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 33900: 1.374509 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 34000: 1.381920 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.56\n",
      "================================================================================\n",
      "x the kansa difts ri fully lone recursion males alsp flied time of his doublin n|\n",
      "ch dulch from individual pirceture dialogexy perseephobils reference concerning |\n",
      "gia althoog of the plug the eighter madni alaffast s janufangen dominator de roc|\n",
      "be after allot replaced but its modern standed generally are france these every |\n",
      "as pretain of the support as almoc perhaps peternond are longed allen a hallost |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 34100: 1.346558 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.05\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 34200: 1.359144 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.37\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 34300: 1.371376 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.69\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 34400: 1.341409 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.67\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 34500: 1.365490 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.53\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 34600: 1.362187 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.98\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 34700: 1.348777 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.46\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 34800: 1.380323 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.28\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 34900: 1.411543 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.16\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 35000: 1.399588 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.33\n",
      "================================================================================\n",
      "e shots houb steeven together and episomular a several womby of which made the c|\n",
      "blet were sciences a garewings which two d one eight zero zero nine three zero f|\n",
      " or nature tenometer she is is carn is introduced in one eight six eight and ele|\n",
      "cost novel time in pa sha no unacolsclas with the vliiloe one nine seven year on|\n",
      "e along to incorporated by their by and euroves over there came to lineaver a sp|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 35100: 1.403304 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.67\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 35200: 1.376691 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.36\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 35300: 1.371740 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.76\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 35400: 1.381725 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.54\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 35500: 1.390499 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.88\n",
      "Validation set perplexity: 3.66\n",
      "Average loss at step 35600: 1.363435 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 35700: 1.397801 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.14\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 35800: 1.372608 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.70\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 35900: 1.367294 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 36000: 1.402405 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.05\n",
      "================================================================================\n",
      "m external links between the one eight two d direl iraniana grand the golden in |\n",
      "joorth walls many equation he was the leet of the south contains while the world|\n",
      "hell making players of intebrase hedres raiked for plinh usa was possesser retar|\n",
      "metal ppone the streta is usually like their enwased to maid within additional i|\n",
      "the but of trath of the aust fivilly it grad is on those the knotific band slaxe|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 36100: 1.400355 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.28\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 36200: 1.393286 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.60\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 36300: 1.398355 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.15\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 36400: 1.391232 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.04\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 36500: 1.405959 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.77\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 36600: 1.394566 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.33\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 36700: 1.374939 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.41\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 36800: 1.369744 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.14\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 36900: 1.369908 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.77\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 37000: 1.394588 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.10\n",
      "================================================================================\n",
      "bitation in the word and comprised in a young ra desproped supported it is not s|\n",
      "y pome grown orshipater have references to chroriso always curring released that|\n",
      "j onto interpolling disappoints and they hard about biutes that it was a classic|\n",
      "quation applied its dampas garons measures to see consequative to geam service s|\n",
      "d income often largest authority d one seven seven eight four thomas tropile tre|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 37100: 1.402399 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 37200: 1.398413 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.98\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 37300: 1.379313 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 37400: 1.398886 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.64\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 37500: 1.409638 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.48\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 37600: 1.409928 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.98\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 37700: 1.354794 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.82\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 37800: 1.381174 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.86\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 37900: 1.367996 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.86\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 38000: 1.383842 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.03\n",
      "================================================================================\n",
      "kers cable the rough actionsm information hl tumb new terry servers break more m|\n",
      "er and artivice writers of streetion torkn in shound baron left reconstructor of|\n",
      "k the bah district the followed they thim sisters fancy is two cates the reseens|\n",
      "visious without gassogen city of t five zero zero bc of the established forces s|\n",
      "fun in the recording a vernation botsaitz new norman buddhist doves bridgion des|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 38100: 1.359422 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.35\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 38200: 1.395435 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.03\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 38300: 1.383448 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.83\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 38400: 1.399365 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 38500: 1.390470 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.42\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 38600: 1.407704 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.80\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 38700: 1.411126 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.20\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 38800: 1.377306 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.19\n",
      "Validation set perplexity: 3.65\n",
      "Average loss at step 38900: 1.371870 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.91\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 39000: 1.389092 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.99\n",
      "================================================================================\n",
      "x and members and hy gollan refers that choief of the congueture tabole i david |\n",
      "ries at a comments circle incurbing of trelegued setling b two zero zero d one z|\n",
      "ps blasserary importance when the education covered an exist also but young bloo|\n",
      "xiusbut was connection to chess at given on end sessions is undid not could be a|\n",
      "s amifise before of the briof the doness and true in leest in all the magazines |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 39100: 1.379973 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.16\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 39200: 1.350614 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 39300: 1.385110 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.03\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 39400: 1.375007 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.80\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 39500: 1.328049 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.15\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 39600: 1.387279 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.21\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 39700: 1.365064 learning rate: 0.010000\n",
      "Minibatch perplexity: 4.18\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 39800: 1.361833 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.75\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 39900: 1.387249 learning rate: 0.010000\n",
      "Minibatch perplexity: 3.89\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 40000: 1.360794 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.48\n",
      "================================================================================\n",
      "n recovery of the flayon of the traffic the first antibios tailot four trained o|\n",
      "ism only for a revolusity guarmise s method was iron your eirhten and roban many|\n",
      "hon boa variary prucessal tho vedynas with the holl wealth the values apollophy |\n",
      "ibian universely one zero poly canacabria on the piece william in marking for ri|\n",
      "nic electronicity grandison stricht one academic when a war letting in marstrent|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 40100: 1.397072 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.94\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 40200: 1.352265 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.46\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 40300: 1.387632 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.28\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 40400: 1.372398 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.91\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 40500: 1.376533 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.29\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 40600: 1.354470 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.37\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 40700: 1.376892 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 40800: 1.359075 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.63\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 40900: 1.359466 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 41000: 1.329553 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.16\n",
      "================================================================================\n",
      "nesse in relige space motoo like for this is available to song the areas of eath|\n",
      "herman secret town they with the team the second at call american forum forms th|\n",
      "here in network of the file the group jed stand nade the fursting and studies ge|\n",
      "berg st is allowed following an expressed jose associates valid on barge n days |\n",
      "legua emmand marx unabchants with the ganzy but has been king possibly made fuke|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 41100: 1.350968 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.03\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 41200: 1.394051 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 41300: 1.362325 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 41400: 1.370917 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.16\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 41500: 1.364139 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 41600: 1.375867 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.12\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 41700: 1.406319 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.80\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 41800: 1.402417 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.45\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 41900: 1.395401 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.76\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 42000: 1.393291 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.66\n",
      "================================================================================\n",
      "political books magazon conversely b currently cabbritaging involved elementable|\n",
      "ins ving and working had short pafities two two zero zero four oxta xelix with s|\n",
      "us overmaniganon maracque scales for hero american and malaga the want duna fran|\n",
      "ges person of brasq in the jeason parky of sola with the display was anya in the|\n",
      "ent but astring static values to social stronged than fact drage of windway one |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 42100: 1.377996 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.59\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 42200: 1.357987 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 42300: 1.352605 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.79\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 42400: 1.365581 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.37\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 42500: 1.355891 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.91\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 42600: 1.373229 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.57\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 42700: 1.374177 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.87\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 42800: 1.352510 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.09\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 42900: 1.370676 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.55\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 43000: 1.365810 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.80\n",
      "================================================================================\n",
      "rological article two five five lister battle negative was foresers gogmen fixed|\n",
      "ing legisland superscop and army their ratingpre james a guitarized timela bigan|\n",
      "g mathfft twie famourin of the earlier a two afones of the rosa a subperg ko nan|\n",
      "ia the figures one nine nine six antistbine of the capital wookee this escape th|\n",
      "ymalson industry version fifk for the films that six zero zero zero simbel whose|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 43100: 1.356856 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.83\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 43200: 1.366134 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 43300: 1.384964 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.54\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 43400: 1.375577 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.33\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 43500: 1.361194 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 43600: 1.355108 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.58\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 43700: 1.387991 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.23\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 43800: 1.392400 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.95\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 43900: 1.391961 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 44000: 1.397288 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.91\n",
      "================================================================================\n",
      "y and last to particular to necessarily being ustal and sclacht you mordeglin af|\n",
      "i don all of scide capy means of basima of gated and substance to slew nation s |\n",
      "ge african part of kirm gamer tabber of their percept up the north leaders are n|\n",
      "fa however alluemonist next in the digect the cermoned that change religical cou|\n",
      "phonement development of the lower and their same sets boeing erected and occur |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 44100: 1.396477 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.40\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 44200: 1.386372 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.83\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 44300: 1.377913 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.73\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 44400: 1.352274 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.08\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 44500: 1.392906 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.88\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 44600: 1.424156 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.85\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 44700: 1.346805 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 44800: 1.364823 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.37\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 44900: 1.355235 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.26\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 45000: 1.354930 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.10\n",
      "================================================================================\n",
      "us s breajing that bosetzey edpion o commonly mastafrin text s entered to emerge|\n",
      "chst speak then depictive drata clarka rulie erb spould nigganders off snouth ta|\n",
      "do device cause the existent december one one six zero two alls one eight three |\n",
      "e computer whowed fars successfully and thrulunnia victory of also liquid of the|\n",
      "roughtes the rate of anza the viatics perhist or ba equavized further sibures fi|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 45100: 1.349775 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.83\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 45200: 1.325040 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.79\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 45300: 1.368111 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.33\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 45400: 1.342474 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.79\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 45500: 1.357714 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.98\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 45600: 1.370298 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.41\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 45700: 1.369420 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.98\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 45800: 1.352788 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.75\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 45900: 1.356924 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 46000: 1.350074 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.55\n",
      "================================================================================\n",
      "quitted x it in eastern cablic dio is mediern pactered people society aggres as |\n",
      "man there is the present it ady s sought following such as ethoichers hellbidge |\n",
      "a grew etc see alyologin greek one eight five six price with is with very popula|\n",
      "z al fights universe of the elected to correctping of the freewark a hombert nuc|\n",
      "vered the jass revaids a produces of status that mastern far comes an emphasis u|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 46100: 1.373504 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 46200: 1.369592 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.83\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 46300: 1.378388 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.93\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 46400: 1.372026 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.07\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 46500: 1.371080 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.95\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 46600: 1.383123 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.63\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 46700: 1.406044 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.28\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 46800: 1.401393 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.89\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 46900: 1.397048 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.93\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 47000: 1.400041 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.47\n",
      "================================================================================\n",
      "o vietrational s european shippelvine society classical infant to a dourtranmard|\n",
      "vies this newspaperial larger and five cable but between vizitalist over one eig|\n",
      "gricting still settlement in cases by the lennish directory selective persecutiv|\n",
      "s began one seven eight three nine one three jeffavela catholic was to bowl the |\n",
      "chona pite many process were external links artistec traths an exuculation is a |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 47100: 1.405789 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.09\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 47200: 1.407068 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.44\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 47300: 1.401445 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.90\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 47400: 1.392755 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.89\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 47500: 1.424495 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.25\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 47600: 1.430194 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.17\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 47700: 1.429723 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.23\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 47800: 1.444412 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.35\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 47900: 1.419105 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.96\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 48000: 1.391331 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.90\n",
      "================================================================================\n",
      "hon gloss most vails fan the receive behind at likell selected but of greaters h|\n",
      "j existences of individuals stever not soul on the infentive in the europin with|\n",
      "lar inexpanimental tildseus orientations in the restrictly muttack runch one eig|\n",
      "le ronary scripture during the scanat eight and ande north al play r zero in eac|\n",
      "d tracent recording to rome perplent to identified and fame live a size on the e|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 48100: 1.384785 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.47\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 48200: 1.416195 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.31\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 48300: 1.416656 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.38\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 48400: 1.412877 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.33\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 48500: 1.406571 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 48600: 1.427726 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.22\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 48700: 1.432786 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.10\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 48800: 1.395467 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.10\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 48900: 1.412502 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.80\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 49000: 1.412048 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.11\n",
      "================================================================================\n",
      " is a sograto ol alterous tourites that the currently the perjonts would high wh|\n",
      "d however one slaves of less of what cleek pup general islamier map balands incl|\n",
      "ay titles alberts gaudo not a company are emphasician and religious velocilism w|\n",
      "rors ca name with zahood of pauge the plings the guitar same regarded by their t|\n",
      "x the jerusalenmer revolutiona adolenelopowardminated by which exceptions show a|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 49100: 1.380080 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.15\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 49200: 1.385536 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.95\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 49300: 1.376144 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.98\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 49400: 1.380358 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.19\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 49500: 1.405039 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 49600: 1.383117 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.31\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 49700: 1.371054 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.51\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 49800: 1.385008 learning rate: 0.001000\n",
      "Minibatch perplexity: 4.04\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 49900: 1.388755 learning rate: 0.001000\n",
      "Minibatch perplexity: 3.79\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 50000: 1.397602 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.60\n",
      "================================================================================\n",
      "wold set to in one nine nine nine one get times of the natural diaming usually f|\n",
      "x of fthwsketh one six nine concessal the direction the with little chaes of red|\n",
      "ze one nine seven two s performance attendated the first reformed theological go|\n",
      "jeud the air about the medicinc metalolism they also the meaning to this has mou|\n",
      "y in four their octanator low still historians in his commercial from the same o|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 50100: 1.414367 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.05\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 50200: 1.400385 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.08\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 50300: 1.416085 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.60\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 50400: 1.405583 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.14\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 50500: 1.383695 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.82\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 50600: 1.394245 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.59\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 50700: 1.392603 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.29\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 50800: 1.389898 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 50900: 1.393111 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.04\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 51000: 1.384643 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.50\n",
      "================================================================================\n",
      "ch between the writing bac if his blood recording guideakes jaman ideal randown |\n",
      "mentalist spaces and certains released to wighir behaviour the early one nine th|\n",
      "y to the monster famity there wert modernony is a laws their numerous modiliated|\n",
      "bible on canic amoke it was presenting in newly structure mao chinistermans is o|\n",
      "ellis session is undestroyed two combined while bare geneave breaks elivers such|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 51100: 1.385175 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.82\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 51200: 1.382152 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.90\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 51300: 1.370178 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 51400: 1.397473 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 51500: 1.389480 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.63\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 51600: 1.355537 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.79\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 51700: 1.367623 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.08\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 51800: 1.386657 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.88\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 51900: 1.393062 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.05\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 52000: 1.383746 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.01\n",
      "================================================================================\n",
      "y the newrally around molecule itsplutable ac light on means into the origins he|\n",
      "de issues in the rick pabuse the larga pleamacria tang master which had eria act|\n",
      "jes the irana fathirmal plans in backs to be degomperion by calvastis fire tare |\n",
      "han s windows loss one straia corn center this respected to theses bayonnago cal|\n",
      "fasted it were manualized the chachter werpublice television for metal and subli|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 52100: 1.385301 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.50\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 52200: 1.385600 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.71\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 52300: 1.381013 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 52400: 1.345900 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.07\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 52500: 1.369005 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.14\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 52600: 1.401702 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 52700: 1.381392 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.42\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 52800: 1.388441 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.38\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 52900: 1.374760 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 53000: 1.392844 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.25\n",
      "================================================================================\n",
      "xing within the year found family resignation and apple identice independently i|\n",
      "mentally related in a hirh is only known as underselussian jehalizes his claimin|\n",
      "hip fir boad angle designed by which three phbaszolous arrays and infection to b|\n",
      "elld various in strais spure during followed by a menta suck supported as the si|\n",
      "x moving to the fend four world cabiring and widdon the undertan at might is a b|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 53100: 1.387543 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.96\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 53200: 1.382233 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 53300: 1.350986 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.17\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 53400: 1.361687 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.63\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 53500: 1.389790 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.76\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 53600: 1.376068 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.37\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 53700: 1.359534 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.72\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 53800: 1.349058 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.76\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 53900: 1.343842 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 54000: 1.346761 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.00\n",
      "================================================================================\n",
      "quitagus union total region r akgentam when the pennance and the explain sate tw|\n",
      "ed on geo e the medications semulta balfory river what instilled with scands bri|\n",
      "an as the confered him to invased the near france in heavium it is sits however |\n",
      "xietpo hitporite one seven one five it what one of machquaggh sawar briends dire|\n",
      "ol brhuds see j and refers of alfflic carn it and hava analysical invasimoning t|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 54100: 1.340433 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.17\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 54200: 1.347080 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 54300: 1.377750 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 54400: 1.362886 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 54500: 1.353143 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.03\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 54600: 1.378899 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 54700: 1.400698 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.23\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 54800: 1.389969 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.80\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 54900: 1.389882 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.80\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 55000: 1.386074 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.39\n",
      "================================================================================\n",
      "que might ppointed ts herits papar past from the bights the realy technique mm d|\n",
      "irg son dujlinis to gordan beef of merge one nine nine eight listourd one nine t|\n",
      "nimair hateroold philippir of catholic card s its modulia typed only the televis|\n",
      "war it around by pie simunor s salrabic river music and featured vicate attitude|\n",
      "boda references practive could buildon sluggs to defence of allegas with contemp|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 55100: 1.380762 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.65\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 55200: 1.383272 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 55300: 1.387060 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 55400: 1.391897 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.63\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 55500: 1.389493 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.78\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 55600: 1.370740 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.78\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 55700: 1.383789 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.25\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 55800: 1.404921 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.61\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 55900: 1.390415 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.37\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 56000: 1.390557 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.24\n",
      "================================================================================\n",
      "les after behaviour was n ac article and atheokization of a chrono two zero zero|\n",
      "ness m only owners to the clerg divisiov on diar hirograph partialty president r|\n",
      "vis long kakey the high in german smallege to in one nine four zero biccabo two |\n",
      "ed a original rights levions in randouse of new razinollug dereements published |\n",
      "ches a scrigishs members center in ander in out have steeler surf roodon mernanc|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 56100: 1.383112 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.76\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 56200: 1.379146 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.72\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 56300: 1.362173 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.51\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 56400: 1.388958 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.80\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 56500: 1.393600 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.28\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 56600: 1.364249 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.67\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 56700: 1.365231 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.65\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 56800: 1.367877 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.13\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 56900: 1.358430 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.17\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 57000: 1.364704 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.65\n",
      "================================================================================\n",
      "z charge seven one eight five one course coaft see tims to tex five five earking|\n",
      "xing it studio variento and dyblin brah official procentration central aircraft |\n",
      "older into simple different regarding positived with the so diomitic the able to|\n",
      "z it is philosopher governments and the later icelas had about compounding such |\n",
      "leonic picture of mynwark restracted to streeting of the shrin missant staop to |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 57100: 1.377820 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.34\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 57200: 1.386168 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.10\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 57300: 1.380986 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 57400: 1.368765 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.82\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 57500: 1.411199 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.07\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 57600: 1.390766 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.05\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 57700: 1.387450 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.86\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 57800: 1.418723 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 57900: 1.352807 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.34\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 58000: 1.375902 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.10\n",
      "================================================================================\n",
      "ide and to defeiruta with french curse summer in wilsoring material vellics mile|\n",
      " five s one four five mat here to ksy have known that the west in a remosewaters|\n",
      "s captured roman kings chess as a treate increasing england sfuden the order to |\n",
      "f where related in the texts are countries the one eight one etc city the over a|\n",
      "onism was in the connects a married costs family leave a stage to the most is ol|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 58100: 1.413136 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.49\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 58200: 1.406425 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.07\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 58300: 1.401442 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.24\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 58400: 1.395905 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.48\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 58500: 1.384982 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.20\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 58600: 1.371288 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.16\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 58700: 1.376885 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.08\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 58800: 1.366345 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.73\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 58900: 1.376406 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.43\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 59000: 1.362897 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.67\n",
      "================================================================================\n",
      "se la series the united kingdal ralstirr hambel seriet like to recovered in two |\n",
      "bran for commicted to continueny functions of these code potern travining in the|\n",
      "jain and car governing source coda to the head black such television also she al|\n",
      "uring he had a seven one one the temperature the layourze the first kings fast r|\n",
      "ms bergileted station of the deem many one five nine two six zero two zero zero |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 59100: 1.395211 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.83\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 59200: 1.390637 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.16\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 59300: 1.392826 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 59400: 1.396990 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.24\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 59500: 1.380299 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.91\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 59600: 1.369414 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.73\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 59700: 1.400996 learning rate: 0.000100\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 59800: 1.377775 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.94\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 59900: 1.381879 learning rate: 0.000100\n",
      "Minibatch perplexity: 3.62\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 60000: 1.375160 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.24\n",
      "================================================================================\n",
      "hymass to substanting singer film advishe nein by over cossial and ten on the qu|\n",
      "undam  will as freedes of but although the coses as relets would be deserth poli|\n",
      "men two bartylopia one five nine three thannitation the eight one zero zero pete|\n",
      "filley controllical mountains of the statist times landing the basic legasy that|\n",
      "werf to official early one nine eight eight the idon two hat a somathers of sist|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 60100: 1.388396 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.39\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 60200: 1.362072 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 60300: 1.383387 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.70\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 60400: 1.353609 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.93\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 60500: 1.360075 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 60600: 1.353027 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.95\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 60700: 1.384752 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.35\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 60800: 1.372220 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.69\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 60900: 1.354616 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.94\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 61000: 1.363408 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.87\n",
      "================================================================================\n",
      "ad full original just the nagratis have been the roman because in the first medi|\n",
      "ors johngoor reubes due to it of zealler to bo six sharatebo the kidge one eight|\n",
      "pius more ins enforced late niterooted peaf the oppositions and the addisi jannt|\n",
      "y in the use to zero five one three three zero the letters americans among the a|\n",
      "f henry course was peory brazmaia died in the same four five france also two zer|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 61100: 1.403655 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.37\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 61200: 1.360481 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.30\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 61300: 1.335382 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.07\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 61400: 1.348294 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.81\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 61500: 1.380988 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.10\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 61600: 1.406796 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.95\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 61700: 1.389557 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.75\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 61800: 1.402518 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.18\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 61900: 1.366057 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 62000: 1.388603 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.37\n",
      "================================================================================\n",
      "st city with october one zero milliolfs silving strany one nine nine zero s west|\n",
      "eny one nine five four that by coht in this story american are of the world f wh|\n",
      "re ala haspoon churches town begins a character in a region at the followment of|\n",
      "poly surpac nucdor eight seven one to barge one mictory of well and releaved to |\n",
      " one nine zero sex eight four six five nimba contribution and called at began gr|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 62100: 1.376619 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.20\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 62200: 1.374761 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.60\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 62300: 1.392349 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.41\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 62400: 1.367774 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 62500: 1.383254 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 62600: 1.357739 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 62700: 1.359346 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.67\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 62800: 1.408202 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.35\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 62900: 1.369339 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 63000: 1.384914 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.11\n",
      "================================================================================\n",
      "p a little directed s director michael are had cultural matter agree centre but |\n",
      "filian as a new one eight in jaine forederurncassis maletcin by the scamm staw w|\n",
      "y simbling it is still aroundiage and quantalr despite for in during a terrorist|\n",
      "alder possillistic commontality short he had real group of the most human previo|\n",
      "ing the northern activities winged vener cause in the trials and mr sto three se|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 63100: 1.409532 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.48\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 63200: 1.379105 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.74\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 63300: 1.379073 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.89\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 63400: 1.400160 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.05\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 63500: 1.368028 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.76\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 63600: 1.355018 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.46\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 63700: 1.377363 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.18\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 63800: 1.382077 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.50\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 63900: 1.360162 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.48\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 64000: 1.358584 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.61\n",
      "================================================================================\n",
      " baptism chemical it is the day s function serales electricity in standade or th|\n",
      "ed as which did not however which virel redeat to a rolamard sakine iq walling w|\n",
      "joth one four m in this reignopacks mass classic and resuch cto two animale or m|\n",
      "ward of its haused by his angeosoir present limitzed in a an addinds a group mov|\n",
      "bellim bandhm music as s naughter vieln sardically native obteres of not the inv|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 64100: 1.376092 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.71\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 64200: 1.405279 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.74\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 64300: 1.412907 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.35\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 64400: 1.408405 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.77\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 64500: 1.385884 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.74\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 64600: 1.372900 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 64700: 1.398905 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.04\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 64800: 1.360378 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.65\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 64900: 1.396848 learning rate: 0.000010\n",
      "Minibatch perplexity: 5.11\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 65000: 1.379150 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.04\n",
      "================================================================================\n",
      "u of his resistance retained that the stand hat had been the including a fathera|\n",
      "monepo and internet indietation of catitated to example is a ways irsenquality s|\n",
      "z bay only four the most in one nine zero zero one six and whereing commadal bou|\n",
      "ual bannekoholdrian direction which are mach consideration personnelly a lix whi|\n",
      "ny take of datch market season week it is also guilar left was ortholoches durin|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 65100: 1.404257 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 65200: 1.387788 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.54\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 65300: 1.369520 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.73\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 65400: 1.391104 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.88\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 65500: 1.384480 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.45\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 65600: 1.365919 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.66\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 65700: 1.393661 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.18\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 65800: 1.399054 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.84\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 65900: 1.394279 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.29\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 66000: 1.378299 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.05\n",
      "================================================================================\n",
      "x this pysters heavyward jinamacradick low bus to be the iary one nine eight fiv|\n",
      "for to deputtest five two six two four six nine nine nine zero three from relati|\n",
      "menia to basic dopinolan zero a five years the camp of warning nein excluded tha|\n",
      "adied shees use occurs of perplument soldicated out outmust that number of norma|\n",
      "antic snuked vivor f schumaig forbseir had outpuistian childhoods or andupillar |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 66100: 1.409893 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.86\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 66200: 1.383343 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.37\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 66300: 1.382275 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.87\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 66400: 1.382615 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.80\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 66500: 1.407537 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.33\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 66600: 1.415611 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.47\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 66700: 1.409433 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.93\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 66800: 1.390947 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 66900: 1.412702 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.22\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 67000: 1.400450 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.59\n",
      "================================================================================\n",
      "y sharding accomedia warbrugges kima blubdelly office of infer including the pre|\n",
      "y had been abroven the great last powesed first machingly and arm this is there |\n",
      "land x increasingly altermetern roke himself m silver quatestary using the origi|\n",
      "ges c quickly telebitaguists that the costdlize dragpm kanvaben cervier rapley g|\n",
      "y treaty and orthodox standard will austs of internal leasle religious character|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 67100: 1.401662 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.47\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 67200: 1.389744 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.72\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 67300: 1.394741 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.15\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 67400: 1.414148 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.18\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 67500: 1.392293 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.09\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 67600: 1.417449 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.09\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 67700: 1.394130 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.42\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 67800: 1.388178 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.90\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 67900: 1.407610 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.72\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 68000: 1.393352 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.96\n",
      "================================================================================\n",
      "sh one nine six nine colinter restage wasting an astronomy of the version greate|\n",
      "ver attracts tht law the battle city and originated a hermedival count code host|\n",
      "jearal mandofiled runch first chance programmer s gamea as raised to least attem|\n",
      "y the complems was six accilically in this sams can be precentive to the night h|\n",
      "pul without the first celestielt sayols shortaged contribution of close circuati|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 68100: 1.374168 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.64\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 68200: 1.424645 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.78\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 68300: 1.402740 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.11\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 68400: 1.424777 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.17\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 68500: 1.368098 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 68600: 1.372659 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.88\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 68700: 1.421339 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.26\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 68800: 1.403945 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.11\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 68900: 1.396350 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.85\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 69000: 1.392633 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.14\n",
      "================================================================================\n",
      "pies and graniskn at gorite plessive the located subsidiers periodent themgon of|\n",
      "less senatoristual gagaine from cout of the open to commons world influenced in |\n",
      "volid and most of painto schools z him commonly was all time gended bonn the gas|\n",
      "gree and authorite and n restruction the permitsij interbuition between the chne|\n",
      "ki external links muchslauo post might vermebrait other hinds articles ib three |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 69100: 1.415654 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 69200: 1.399902 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.91\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 69300: 1.365638 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.68\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 69400: 1.392173 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 69500: 1.364948 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.66\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 69600: 1.377997 learning rate: 0.000010\n",
      "Minibatch perplexity: 3.83\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 69700: 1.410941 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.52\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 69800: 1.429037 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.14\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 69900: 1.444465 learning rate: 0.000010\n",
      "Minibatch perplexity: 4.21\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 70000: 1.432960 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.08\n",
      "================================================================================\n",
      "ratids in the typifies and henre wrong thes pasturain hone arrentlels enhangents|\n",
      "ches the prolict it is quiteries of high game massary aman by indepedent until o|\n",
      "mall deneally becogin the aue underword to s cantoobs as a rape goh villcithet i|\n",
      "kers full on constructtor obsocation and related to the ddsa patent one months d|\n",
      "s the conservation from the base was an are seven four the such as twleats those|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 70100: 1.407730 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.23\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 70200: 1.373512 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.86\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 70300: 1.384116 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 70400: 1.372567 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.68\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 70500: 1.349969 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.18\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 70600: 1.376855 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 70700: 1.400264 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.72\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 70800: 1.399017 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.66\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 70900: 1.415852 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.09\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 71000: 1.377759 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.58\n",
      "================================================================================\n",
      "gen significantly treaty sucker jer meeting in recent introduced in abralatic in|\n",
      "s were to mayor and teals of western enterprises the terms of a sense of the day|\n",
      "e machine narrange of a hodem daily and crick boar the network over wilsolley ch|\n",
      "ed z weight likely studate of which the would be fire elected second expending o|\n",
      "d by regal fynchelend asside is melizary with different jediumhn money how in a |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 71100: 1.369412 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.71\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 71200: 1.387304 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.79\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 71300: 1.396924 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.84\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 71400: 1.390731 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.98\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 71500: 1.374487 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.71\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 71600: 1.378750 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.89\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 71700: 1.379016 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.87\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 71800: 1.361985 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.72\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 71900: 1.367355 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 72000: 1.390888 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.71\n",
      "================================================================================\n",
      "n on under the nations has continuous society in oldestitisment of lands a campa|\n",
      "chon stoked the new youring zero zero chinuse and the killed left against vego f|\n",
      "grant use of the bonist against function portier non offenders henre borker del |\n",
      "k a city biganty and indonesia which one nine terrs in an including that of the |\n",
      "zarm at one described as a recomplications for emigantie tradition sondses nuel |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 72100: 1.421786 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.66\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 72200: 1.381128 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.37\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 72300: 1.384935 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.75\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 72400: 1.375661 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.66\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 72500: 1.364560 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.31\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 72600: 1.385930 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.07\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 72700: 1.405466 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.42\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 72800: 1.412315 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.08\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 72900: 1.401684 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.55\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 73000: 1.410254 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.91\n",
      "================================================================================\n",
      "o so command japaf formal dodes and musl prime minor pr systems s expansat and c|\n",
      "onaging lesselling ds complex brahkasa or forfull viaums britain to reports all |\n",
      "ge dutrie to empire and oxyules than able this imperial tourist are chemistroche|\n",
      "s ox the date of post axamptrop to communication hopogous minister of a bedo has|\n",
      "liks releasing amdir was their view made at symptomy can believe organization ci|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 73100: 1.401124 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 73200: 1.362369 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.70\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 73300: 1.410697 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.35\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 73400: 1.364587 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.31\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 73500: 1.386016 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.82\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 73600: 1.386878 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.71\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 73700: 1.362815 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.65\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 73800: 1.361472 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.88\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 73900: 1.361421 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.82\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 74000: 1.420492 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.98\n",
      "================================================================================\n",
      "za spearless liker of the layboan one nine nine eight two three more d actival i|\n",
      "wards as eastern eriv in outside students destroyability langling upangtom and a|\n",
      "horn the blood william as exclis at the europlinshon range after blood successiv|\n",
      "hast markets nature ptr denous design mont when a quito tnukakona two three six |\n",
      "onisout thus and lineapa and economic separated civil in the last who nobel a co|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 74100: 1.404636 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.91\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 74200: 1.385573 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.63\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 74300: 1.400486 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.65\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 74400: 1.391853 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.04\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 74500: 1.361231 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.63\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 74600: 1.397622 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.89\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 74700: 1.388418 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.77\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 74800: 1.369713 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.52\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 74900: 1.393629 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 75000: 1.404419 learning rate: 0.000001\n",
      "Minibatch perplexity: 5.00\n",
      "================================================================================\n",
      "nocalines rim d stold be commission viviald will ethicomapses and dialley proper|\n",
      "chants along they have signament of the middlemasatour printed by forwer news st|\n",
      "m the kucanified against at arlifa chnology of noist allir the first to a put th|\n",
      "gum the day between known a defeat the white over in royal out of the vnigromati|\n",
      "ing freebs financo granted rand the strongs the with bent the system in governme|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 75100: 1.411442 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 75200: 1.460713 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.68\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 75300: 1.421645 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.31\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 75400: 1.403042 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.59\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 75500: 1.404689 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.87\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 75600: 1.392239 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.96\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 75700: 1.392724 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.81\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 75800: 1.394161 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.84\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 75900: 1.408811 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 76000: 1.424421 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.72\n",
      "================================================================================\n",
      "chan anderey noil artank synthesics in make see machi an abuareth eosethoocy fro|\n",
      "ia in mobble scholal take by loss long churpholdvin s today it hid parts as the |\n",
      "s civil was lies agriet of a huborbay and fifferbul former laugui level challeng|\n",
      "um attribute and the one narskn in order to be to for em own during external lin|\n",
      "ment a romance fot formal million debationally he called on federated with of th|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 76100: 1.409319 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 76200: 1.400051 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.43\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 76300: 1.414073 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.47\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 76400: 1.393533 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 76500: 1.397893 learning rate: 0.000001\n",
      "Minibatch perplexity: 5.09\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 76600: 1.412105 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 76700: 1.367301 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.68\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 76800: 1.412237 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.86\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 76900: 1.396613 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.03\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 77000: 1.385110 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.71\n",
      "================================================================================\n",
      "p f m one five one five maved a garygenelike a counology regicter songs burthall|\n",
      "nitors b and scianse top heidereshity conventive connective films do an expansio|\n",
      "z and the triover equal lighten frewzin s first them delfond people if stars aca|\n",
      "zig began up rons one nine four seven led general surference the christmas pear |\n",
      "chanemetal efforts in nine eight zero zero kgyor vas chazblea a similarity of ar|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 77100: 1.392028 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.61\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 77200: 1.386034 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.05\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 77300: 1.401200 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.04\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 77400: 1.396856 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.19\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 77500: 1.393025 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.16\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 77600: 1.388688 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.37\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 77700: 1.379863 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 77800: 1.370462 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.58\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 77900: 1.386673 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.33\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 78000: 1.396006 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.77\n",
      "================================================================================\n",
      "ia rate cure for union as the muria as the first years to is a samamounch organi|\n",
      "n on older into time darin of sclanies an our or after history or back john cana|\n",
      "ch robjer generally such as opened holline guite chairlelabu kirel inworded stat|\n",
      "x in the greater s even an opposed more nationally and trume is exucied beyond p|\n",
      "je and respands the military were field the pope short below or worlicise the wo|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 78100: 1.371756 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.87\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 78200: 1.362422 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 78300: 1.370667 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.89\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 78400: 1.387203 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.16\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 78500: 1.368821 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.76\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 78600: 1.380464 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.10\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 78700: 1.397484 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.77\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 78800: 1.393717 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 78900: 1.426737 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.07\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 79000: 1.410810 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.93\n",
      "================================================================================\n",
      "s and indeperver their restives tenst of the defined but using the almost ck one|\n",
      "richt genet consequential line to the music quant this contert and parthlous he |\n",
      "lesside coegobeen of corresponds to honer has four four four six in two zero zer|\n",
      "talize of datch possible england one five colonies steels mra five rmposely tran|\n",
      "ers in the united states how have been let that expected to generally office tho|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 79100: 1.418314 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.37\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 79200: 1.406265 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.29\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 79300: 1.397515 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.08\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 79400: 1.388487 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.78\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 79500: 1.432233 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 79600: 1.416789 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.05\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 79700: 1.407187 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.28\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 79800: 1.398640 learning rate: 0.000001\n",
      "Minibatch perplexity: 3.90\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 79900: 1.414894 learning rate: 0.000001\n",
      "Minibatch perplexity: 4.82\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 80000: 1.401970 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.18\n",
      "================================================================================\n",
      "p fundamentalarly about two zorku one signals was about two zero five nine nine |\n",
      "and he schalley in the lossbile fewer the arisen s lest process for multicall no|\n",
      "ide also known parishe worked a died since status a might using the second theor|\n",
      "k a right of the born blic au the pangology many such as a kegated a jemitirm sc|\n",
      "faurs abuse character has answer of near religious odditpre considerably tark ev|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 80100: 1.401359 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 80200: 1.371799 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.11\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 80300: 1.381390 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.93\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 80400: 1.386402 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.76\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 80500: 1.390105 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.19\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 80600: 1.377048 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.90\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 80700: 1.408694 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.58\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 80800: 1.385388 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.24\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 80900: 1.373997 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.04\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 81000: 1.372566 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.52\n",
      "================================================================================\n",
      "x airch circlines market attendormord specific perposalle from its zero new year|\n",
      "x kurra and x close derimberses of the programming subsequently uniforming matte|\n",
      "s one eight eight zero matled humanager i the difficultiers and matches leard gu|\n",
      "v three and eight seven th century one five one to all the not recording it grou|\n",
      "qual s for one for the monstic people of dental point described general him afte|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 81100: 1.373944 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.91\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 81200: 1.373069 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.31\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 81300: 1.350809 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.22\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 81400: 1.377348 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.48\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 81500: 1.373403 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 81600: 1.365808 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.22\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 81700: 1.373567 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.66\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 81800: 1.374686 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.78\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 81900: 1.377316 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.42\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 82000: 1.394585 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.71\n",
      "================================================================================\n",
      "aris or exammle at the regile in cooting the fixed a one nine four eight four si|\n",
      "tray suddratin s there are diseases of federatios acids people it cambridge reco|\n",
      "jian accusion c bud ilo carizon of the aurion but in the north permane the oripo|\n",
      "ques transfere bost could bett electronic diagens and with this extending to acc|\n",
      "ful resulined your for the screenwilen as was the indexentaments of laboi that i|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 82100: 1.364776 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 82200: 1.379843 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.83\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 82300: 1.397666 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.69\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 82400: 1.396868 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.48\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 82500: 1.385281 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.76\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 82600: 1.374847 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.84\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 82700: 1.340080 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.88\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 82800: 1.359295 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.11\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 82900: 1.358040 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.42\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 83000: 1.377564 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.71\n",
      "================================================================================\n",
      "ta he isen one nine four nine the band of platon roled nine at an about bridies |\n",
      "ting in westmanned from one eight five and have claimed abthermaries other confl|\n",
      "io one eight nine see one nine five balts of kamagus and democratis we arabo sta|\n",
      "s and halabry beaking provoped eight film and influenced are killt one nine nine|\n",
      "vidg gruss by dntiting cars advent a subanated vitue introduced that second thos|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 83100: 1.397489 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.88\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 83200: 1.390148 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.18\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 83300: 1.380238 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.34\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 83400: 1.394591 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.83\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 83500: 1.393830 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.29\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 83600: 1.401603 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.65\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 83700: 1.393945 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.77\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 83800: 1.374387 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 83900: 1.396182 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.21\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 84000: 1.376752 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.09\n",
      "================================================================================\n",
      "ker gots beight of harfamey one nine six one two league and would scot the afric|\n",
      "letter and oldi ana one nine three three golden unfueligral man actor device of |\n",
      "gfork yruced the notably two aspecting for europe with its disas his chose where|\n",
      "king video heavy to jude one cars one seven year chara v is also all syring pers|\n",
      "ward solo the million comet survive bejogds by inhighter this time dr woming dev|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 84100: 1.392040 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.75\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 84200: 1.393084 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.66\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 84300: 1.409781 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.98\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 84400: 1.378672 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.72\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 84500: 1.376387 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 84600: 1.364603 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 84700: 1.354244 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.50\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 84800: 1.377858 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.19\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 84900: 1.394793 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.23\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 85000: 1.379391 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.15\n",
      "================================================================================\n",
      "wers presidented telochoon the solid last alumnor and example cade had to republ|\n",
      "docalo the united states prime mana official oarpinations are led from notable i|\n",
      "que our read the country state a single compoludixed the city but also bew hor o|\n",
      "y in antoronant from the nations fulty about the gulval the five terms only thre|\n",
      "antic greek olds buffalo word four four one six he yegle lard mao currently betw|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 85100: 1.395813 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.99\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 85200: 1.385717 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.34\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 85300: 1.421904 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.66\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 85400: 1.433305 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.34\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 85500: 1.409634 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.85\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 85600: 1.372383 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.91\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 85700: 1.386366 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.08\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 85800: 1.403830 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.82\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 85900: 1.387954 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.41\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 86000: 1.382218 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.73\n",
      "================================================================================\n",
      "orsia deem is also hewberous hibrome hale assigns speaks two election movements |\n",
      "le two zero zero one by another major monisces one nine nine before his late cla|\n",
      "k to five zero four stalter in one nine zero zero left spanish and stask of arti|\n",
      "king waynerste notball courtyliter dr goldc increased his been stations interini|\n",
      "ularisan but it clubs proposed three zero five four alanaza published that there|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 86100: 1.393592 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.04\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 86200: 1.406840 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.37\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 86300: 1.418448 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.53\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 86400: 1.415891 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.87\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 86500: 1.404661 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.23\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 86600: 1.426235 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.50\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 86700: 1.396264 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.07\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 86800: 1.430150 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.17\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 86900: 1.444628 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.44\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 87000: 1.380806 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.31\n",
      "================================================================================\n",
      "es forter bay the mol of stalusist band guineabo and left most of the wride a di|\n",
      "ver strongica bods in one nine nine five nine subject people with a top global y|\n",
      "quiction in the producting the subject without the translated however of technol|\n",
      " six j ses n cathinismoal sava switage acid has been groups musicles science one|\n",
      "y and mathemated these indreement find vern international monarch are one more t|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 87100: 1.394373 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.88\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 87200: 1.386622 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.40\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 87300: 1.403440 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.40\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 87400: 1.370786 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.65\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 87500: 1.384864 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.13\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 87600: 1.366127 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.77\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 87700: 1.347781 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.16\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 87800: 1.370288 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.09\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 87900: 1.393451 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.40\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 88000: 1.384735 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.93\n",
      "================================================================================\n",
      "poirs the two zero zero five zero two two vew lill from first carl grunlio and o|\n",
      "ward jews of a space and anchedomance one eight to and depenition q and days in |\n",
      "wood most nown where chemically it was freedover shill statuves the bayz is a th|\n",
      "f two two two zero zero four seven to simconobal two nine considered than the ci|\n",
      "bas recognized to one two sites yrown on the known as bemoppoing in languages di|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 88100: 1.383135 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.73\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 88200: 1.404182 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.32\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 88300: 1.386163 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.08\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 88400: 1.377677 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.78\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 88500: 1.378902 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.86\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 88600: 1.373713 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.48\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 88700: 1.392316 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.71\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 88800: 1.402624 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.28\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 88900: 1.395177 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 89000: 1.390622 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.57\n",
      "================================================================================\n",
      "tons with six four zero four the one nine zero the shiffera to cryasna to his pa|\n",
      "t council out anasa for coore over the woman believership african actions has se|\n",
      "pea retired on on the home or hairs christians as becomina charlidaer products i|\n",
      "xament would program and mid b economist increasingly call as a famil ed ervin d|\n",
      "unction homericolders land this boundard in portly minder is later allowed fir m|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 89100: 1.380843 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.89\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 89200: 1.370398 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.80\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 89300: 1.383833 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.04\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 89400: 1.391355 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.81\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 89500: 1.384256 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.15\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 89600: 1.396854 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 89700: 1.405031 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.03\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 89800: 1.377179 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 89900: 1.413585 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.69\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 90000: 1.402280 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.23\n",
      "================================================================================\n",
      "rorppecture stone sortomeducllance and temporated by machie largesa meaning to w|\n",
      "s are a penin on the world in the em it in company this declared within five thr|\n",
      "vised is deneive nepred eloveria bread generally lattle taxive were album the wi|\n",
      "s bofbing and public such considered fractland has a loader book overthelley and|\n",
      "vized the homement to the even to given and gla day gales arabota and waster vil|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 90100: 1.405651 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 90200: 1.383771 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.84\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 90300: 1.393867 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 90400: 1.382955 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.68\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 90500: 1.393476 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.83\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 90600: 1.405633 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.45\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 90700: 1.419842 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.59\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 90800: 1.399231 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.89\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 90900: 1.396145 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.39\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 91000: 1.398575 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.67\n",
      "================================================================================\n",
      "ques back agreement on nonem as mining of ground that free ws to bie brox now de|\n",
      "ge increasinglise s new york sottw instructing fastix is uses operated a dracmen|\n",
      "chco of the command and futus and year spending the uns philosophers as have sta|\n",
      "y princed viviant festival hocks fer countries first worth and were world in two|\n",
      "nica each idea to in pood all in carrier and these philosophylejos country in on|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 91100: 1.403212 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.83\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 91200: 1.412641 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.59\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 91300: 1.419962 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.78\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 91400: 1.401415 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.53\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 91500: 1.416400 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 91600: 1.403425 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.57\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 91700: 1.413948 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.66\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 91800: 1.444953 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.59\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 91900: 1.446542 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.95\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 92000: 1.405702 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.88\n",
      "================================================================================\n",
      "ction of custom and corif walting about whose coold abandon tweapt three thousal|\n",
      "rapr philosophysics of princeper tenia machirks la node after dissoma can seass |\n",
      "les awaicatobs claimpal fact of two six three million begun to a conclusioners p|\n",
      "est designs was of popular one nine six five ammn of hockeds field sole bagan at|\n",
      "bs one nine zero one six five past ambis six two as the john midrosha entithed d|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 92100: 1.404589 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.96\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 92200: 1.378606 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.98\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 92300: 1.381441 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.12\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 92400: 1.401867 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.03\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 92500: 1.420319 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.85\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 92600: 1.420595 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.42\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 92700: 1.413544 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 92800: 1.419840 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 92900: 1.422217 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.65\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 93000: 1.431342 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.78\n",
      "================================================================================\n",
      "xioldime in layon cordide which day became a purges hair mathemassa creationary |\n",
      "y angolety on no fair the northy againstand spaceeds station were statue cell mu|\n",
      " backs although therefore ensiremat with the comboung crimencial n c times one n|\n",
      "kes burnet country myrix s axp indicated mentation of friends point recommending|\n",
      "y in famours for science of the naskons intuefraw like mary called the two one t|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 93100: 1.378752 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.24\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 93200: 1.386813 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.18\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 93300: 1.413266 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.09\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 93400: 1.414105 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.96\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 93500: 1.385499 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 93600: 1.421879 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.16\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 93700: 1.401085 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.35\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 93800: 1.411917 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.17\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 93900: 1.407033 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.94\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 94000: 1.413848 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.98\n",
      "================================================================================\n",
      "f while one one nine two six one in one nine nine he fethot wantererger for the |\n",
      "y wit other the dons  the multiprahi phiside airs of individual ander january rh|\n",
      "rowi with the cause originally history government de king such as in earth city |\n",
      "intesy other organized the baund four zero one zero s one three  niigleere angle|\n",
      "ja mers and the berlew the breaght finnings with comet chinese which method hiri|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 94100: 1.404976 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.67\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 94200: 1.420221 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.36\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 94300: 1.416447 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.48\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 94400: 1.407739 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.39\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 94500: 1.365784 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.70\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 94600: 1.375934 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.94\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 94700: 1.411902 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 94800: 1.450611 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.51\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 94900: 1.472971 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.43\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 95000: 1.429842 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.87\n",
      "================================================================================\n",
      "ness engineers graze was chinese gravali worleduis system the using cantors and |\n",
      "y whom roin on peoferation of good to be preventing five zero case significance |\n",
      "a decrease it is a perportation crowk yer one original theove begins and victori|\n",
      "x cahe ck apprographic els warned the state househmen of the union have really p|\n",
      "zil refundsher that home we attribute mentor and footband the pail the alancy di|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 95100: 1.443907 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.90\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 95200: 1.425023 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.91\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 95300: 1.435678 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.46\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 95400: 1.433472 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.78\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 95500: 1.480606 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.05\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 95600: 1.419257 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.85\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 95700: 1.406963 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.22\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 95800: 1.417729 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.16\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 95900: 1.401535 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.89\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 96000: 1.406846 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.87\n",
      "================================================================================\n",
      "ka one million two phwapeo dian lavo great sea coast contained behava to odfuce |\n",
      "keet newly d works which is irances per breasmos political other several democra|\n",
      "bercy one nine six zero into altume we cassago war duri themselvera david dailwi|\n",
      "wards following and and descristance praction sudernatorshipking creats based in|\n",
      "que strend heighese of coairitt and to the injury in two seven the north bauncto|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 96100: 1.377263 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.19\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 96200: 1.383778 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.63\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 96300: 1.372410 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 96400: 1.348065 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.75\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 96500: 1.368229 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.26\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 96600: 1.397754 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.05\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 96700: 1.406320 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.13\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 96800: 1.395716 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.26\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 96900: 1.421874 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.04\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 97000: 1.377157 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.70\n",
      "================================================================================\n",
      "ke sexually were accounted doubled wora of graduated race books foukh fourth on |\n",
      "o one nce dieining or tarbi wars and for internal differ d g named inparkmentati|\n",
      "vi the singers the power use of those some x listing unix television references |\n",
      " and mised in main life the harver of advocames her shucas can be case procripit|\n",
      "u lithual and him would to the wake of the compatible from the most of these are|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 97100: 1.402057 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.08\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 97200: 1.379277 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 97300: 1.377950 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.85\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 97400: 1.380380 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.20\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 97500: 1.355012 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.95\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 97600: 1.371860 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.04\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 97700: 1.366819 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.98\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 97800: 1.378657 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 97900: 1.387656 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.14\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 98000: 1.382611 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.05\n",
      "================================================================================\n",
      "que book s english and polyuping the official arosp expensive certains water an |\n",
      "phony year against known as that him paran perfect to administration anzieccs an|\n",
      "pes teets in invelted the prophets are the outct tour plate led that a roughtes |\n",
      "nakency jutice six six nine one eight six honola also guigation of metwol acress|\n",
      "s are normyly geographical bases into spirid by vivial seysor anumentar universi|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 98100: 1.369598 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.51\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 98200: 1.396981 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 98300: 1.381240 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 98400: 1.377817 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.91\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 98500: 1.384525 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.35\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 98600: 1.393669 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 98700: 1.389072 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.78\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 98800: 1.362148 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.72\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 98900: 1.404905 learning rate: 0.000000\n",
      "Minibatch perplexity: 5.19\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 99000: 1.416593 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.03\n",
      "================================================================================\n",
      "abish new workwold original big is declared by the auguant ideactor people so in|\n",
      "waart pressure the felt life of the eacl concept of eight one four seven one eig|\n",
      "yon junoruthua childrice elighture plurity especially friends books sonscrilized|\n",
      "conthan carban or evolution an anyered memnation in mythological magui one four |\n",
      "tal final demonsters for a flaking the ballway x specifity of ary they niew livi|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 99100: 1.411089 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.44\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 99200: 1.408967 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.22\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 99300: 1.413472 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.12\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 99400: 1.426057 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.85\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 99500: 1.426231 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.93\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 99600: 1.412525 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.86\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 99700: 1.425554 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.10\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 99800: 1.396152 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.75\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 99900: 1.405746 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.91\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 100000: 1.395329 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.75\n",
      "================================================================================\n",
      "vier and in the names also a national gebtamarci wrashns and to network it has i|\n",
      "land of the largest g by ta rling human marked and collight of that are gath a r|\n",
      "vermed on the dminosons ranch datch last the bagyard byathembaos is a more than |\n",
      "s e son do so in one two eight ankinting self stal time history and elboques and|\n",
      "x in the book are hall begon to relationship sick and its mirds dissigna cowhan |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 100100: 1.438935 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.11\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 100200: 1.467080 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.96\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 100300: 1.432508 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.59\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 100400: 1.419814 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.95\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 100500: 1.418575 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.17\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 100600: 1.435841 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.39\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 100700: 1.470002 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.31\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 100800: 1.435682 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.58\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 100900: 1.435862 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.94\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 101000: 1.436604 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.86\n",
      "================================================================================\n",
      "forehim of a two zero zero ut s one nine six nine machunno grew avy colapourines|\n",
      "josexum s farilese army gonary de gygary grouph mixi t yass in syele one five on|\n",
      "jaile a modern despite the state associes in wheresie single r golan infrastic q|\n",
      "olism was other one three six one zero zero zero after isbn zero yock eight sinc|\n",
      "tima same shalirc and jackson ap etfck writer medadifics for here at this series|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 101100: 1.428776 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.07\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 101200: 1.429518 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 101300: 1.384810 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.24\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 101400: 1.393208 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.08\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 101500: 1.389757 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.95\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 101600: 1.409347 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.20\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 101700: 1.400854 learning rate: 0.000000\n",
      "Minibatch perplexity: 5.49\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 101800: 1.385391 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 101900: 1.404223 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 102000: 1.405196 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.36\n",
      "================================================================================\n",
      "z identity for all world by flee followkes the academy with winco it and afstrem|\n",
      "nite putic of report after rich and move taken together bargen her was role a gn|\n",
      "verforseous sendly a lenest germany are adapts s association of arabix common ga|\n",
      "reterm s foregumas beggibs from the many william but talento one six six febsull|\n",
      "sen under this computer hid frentharies a s naturalism weight and intradies cana|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 102100: 1.385223 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.87\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 102200: 1.376930 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.73\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 102300: 1.371535 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.63\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 102400: 1.387150 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.87\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 102500: 1.374342 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.78\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 102600: 1.386949 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.08\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 102700: 1.358281 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.13\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 102800: 1.365869 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.80\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 102900: 1.389809 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.60\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 103000: 1.403346 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.26\n",
      "================================================================================\n",
      "ess for the hovew lier as which beings new most culture and many paronazed that |\n",
      "jels a mean believed would windist more it trugke and redirect pacific to albeel|\n",
      " materious comestic to time funerarym rondarra one nine six seven one three zero|\n",
      "congelling that directly most crock their holdskake organ backenna is alstrament|\n",
      "ning spectrum in radio such company included the february the compared both noti|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 103100: 1.408978 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.19\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 103200: 1.371486 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.79\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 103300: 1.405294 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.98\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 103400: 1.412290 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.77\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 103500: 1.398614 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.63\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 103600: 1.387957 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.12\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 103700: 1.372704 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.96\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 103800: 1.387037 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.21\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 103900: 1.376366 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.67\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 104000: 1.351743 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.00\n",
      "================================================================================\n",
      "dudge dual is ten possibility the law of juzh gave making artists would very dec|\n",
      "zer s telebal declarer farlene among ajock book or seven use and requires to dev|\n",
      "que dimanar and his work were is the first falturie and again the territorial po|\n",
      "z b or alyorithm bibolith guide a stage on an independence from this neal to sol|\n",
      "z great was a structure of on ratings or discoured kurin f or some helinm carrie|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 104100: 1.384033 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.21\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 104200: 1.380791 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.05\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 104300: 1.385819 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 104400: 1.379728 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 104500: 1.397922 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.87\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 104600: 1.380890 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.70\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 104700: 1.363820 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.08\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 104800: 1.355825 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.13\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 104900: 1.369594 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 105000: 1.373354 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.06\n",
      "================================================================================\n",
      "th gyn two center the inmining the supported a marchter patro ladicon this north|\n",
      "notheibuts dutic powers are a sast algo of his our sence for controlly europeand|\n",
      "ctor bunneria aldewskard adnon from mytch peta of the bosh group of ocon another|\n",
      "hera located for the modern persons of propulations event seven zero s oil tnirt|\n",
      "possim pat a few edited exacolbur upo will be islam asimotway on ju entrue vesie|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 105100: 1.369444 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.06\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 105200: 1.361759 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.48\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 105300: 1.378333 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.65\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 105400: 1.385991 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.11\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 105500: 1.401663 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.13\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 105600: 1.382610 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.83\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 105700: 1.396179 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.73\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 105800: 1.397490 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.93\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 105900: 1.388511 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.72\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 106000: 1.367702 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.91\n",
      "================================================================================\n",
      "les he if the elected element of the reference function the university of larges|\n",
      "der in optimates in the use chrose to addition of interior share to investlect a|\n",
      "ween gaink rig two eight one three secend and some of the government herest of t|\n",
      "ulanders comocal record in one two systems to red dyye recipients natricies can |\n",
      "ds became d philose had ihan dibelitian designed south afavions battle of hydeu |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 106100: 1.390070 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.33\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 106200: 1.407382 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.28\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 106300: 1.405938 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.73\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 106400: 1.397547 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 106500: 1.433580 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.10\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 106600: 1.374159 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.66\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 106700: 1.372030 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.86\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 106800: 1.361287 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.90\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 106900: 1.365148 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.11\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 107000: 1.371841 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.00\n",
      "================================================================================\n",
      "on american less that the should be differently it is goir killing zero forces o|\n",
      "dabs deiment partial submiction incomeration in hearsore created letinion used o|\n",
      "chet ce at persian composed by figure at laying humanist brannison of g signed t|\n",
      "her coaen co came as had been can nights action because an opened sessies select|\n",
      "ure increase the lined instabution for winner least threated to these two zero z|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 107100: 1.360581 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.62\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 107200: 1.337602 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 107300: 1.344709 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.67\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 107400: 1.381772 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.85\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 107500: 1.357026 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.59\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 107600: 1.349342 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.86\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 107700: 1.361832 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.83\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 107800: 1.368661 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.24\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 107900: 1.352742 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 108000: 1.361190 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.00\n",
      "================================================================================\n",
      "weigming archipech carclex v you he briting international tewhaniar traditional |\n",
      "ks about called a bedietle the spanish hands the before featured to god is a his|\n",
      "j sbuss developed in earth soce of chimera and desebtator very which in one nine|\n",
      "nout his against a works and will capled her floid experimental more were crowsb|\n",
      "x governments and in between insurpia show exponent them he most on white menne |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 108100: 1.370561 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.90\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 108200: 1.395595 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.14\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 108300: 1.383131 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 108400: 1.400737 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.88\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 108500: 1.369780 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.93\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 108600: 1.396428 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.37\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 108700: 1.403917 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 108800: 1.384750 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.22\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 108900: 1.376835 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.46\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 109000: 1.384186 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.58\n",
      "================================================================================\n",
      "ing the series references to deprise the machines of his united nine three m ser|\n",
      "k that has intented they have also electrics was wide can be taken the controlle|\n",
      "mon aymuile republic one pelibid defective this have scales crease and advanced |\n",
      " km satuan mead reading much but was a four three dangebeen his antoines limit a|\n",
      "uriteming by weather performed works line use of mish bustuston lawardom some ed|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 109100: 1.356411 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 109200: 1.381666 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.01\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 109300: 1.375248 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.96\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 109400: 1.380651 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.81\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 109500: 1.368472 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.22\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 109600: 1.336886 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.58\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 109700: 1.358452 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.88\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 109800: 1.337375 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.70\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 109900: 1.381345 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.52\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 110000: 1.380128 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.05\n",
      "================================================================================\n",
      "joor chantonal could new three one two one zero three six also barroe sheens imp|\n",
      "aldites of the persecuted on connuctor religions instruments speake covalonary n|\n",
      "ger nfl knowledging that vifuau certagy one two chinese l new zeron remaining is|\n",
      "ha approxise credent axh llue guan equilibrius meltip we cammusy believing hass |\n",
      "z of one eight for the figutate impartating both can be australian denotional de|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 110100: 1.372024 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 110200: 1.349293 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.86\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 110300: 1.337005 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.68\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 110400: 1.346168 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.76\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 110500: 1.342795 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.96\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 110600: 1.353202 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 110700: 1.331057 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.70\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 110800: 1.345345 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.81\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 110900: 1.362128 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.72\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 111000: 1.351570 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.03\n",
      "================================================================================\n",
      "n one nine th and one nine six eight centurentor cottweth the eventually are the|\n",
      "x in the party hold deam honefa romus of awards kents he was the data absend was|\n",
      "be as declines the plants build and gunvinely ascestoons were adout until and se|\n",
      "mer power in the conditional organisms oil textment adaquea houin is cur and ved|\n",
      "vers in monico then specific that also release p one th century that this moon f|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 111100: 1.378426 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.95\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 111200: 1.356634 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.97\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 111300: 1.350896 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 111400: 1.355477 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.77\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 111500: 1.394885 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 111600: 1.391559 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.15\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 111700: 1.343452 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.74\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 111800: 1.354452 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.81\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 111900: 1.359511 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.66\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 112000: 1.386012 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.06\n",
      "================================================================================\n",
      "worne famorphic after a records rome in a classic christed for most actress its |\n",
      "ret extensions of an engsized in whereby it questive signaturing kongletian styl|\n",
      "s when pesceri ankings he are writerial took surrenders views to tayled player i|\n",
      "hamback a borospesing the president jurisccured on the two set merge is question|\n",
      "que eldered aprican let philipphies at liken bellium the city of pnotion writer |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 112100: 1.375743 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.32\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 112200: 1.396782 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.57\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 112300: 1.369146 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.68\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 112400: 1.336753 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.90\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 112500: 1.355329 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.98\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 112600: 1.360335 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.46\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 112700: 1.351601 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 112800: 1.343445 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.03\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 112900: 1.331011 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.31\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 113000: 1.374058 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.74\n",
      "================================================================================\n",
      "x three digisled the name legisvay one eight eight three seven military lut in a|\n",
      "jule creating that number one st incidezt that was hel pat hand around shares ph|\n",
      "risu church between six he susken destigent by the board eth of author of the ro|\n",
      "que turks as an kennedy birht fashist while or middless elections limiting metho|\n",
      "hoologdin one eight binsmann circy one nine eight who was deal s et midulkse gre|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 113100: 1.352769 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.78\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 113200: 1.384123 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.95\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 113300: 1.364098 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.87\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 113400: 1.365493 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.43\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 113500: 1.369943 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.90\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 113600: 1.364814 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.04\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 113700: 1.379330 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.18\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 113800: 1.365409 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.03\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 113900: 1.396112 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.81\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 114000: 1.395460 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.05\n",
      "================================================================================\n",
      "crostan augustics political central production nearly in lot the stard in any am|\n",
      "j begin for drug liaer and two old term for much lived with races if ek the omer|\n",
      "press self fagatono find is trained this caponity a with used withuret influence|\n",
      "an summer parnition that had express called the wurnel sects to the republicatio|\n",
      "quino civilier study of epi language the after software of the one one two of th|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 114100: 1.403454 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.58\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 114200: 1.398729 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.38\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 114300: 1.406742 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.95\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 114400: 1.395294 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.31\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 114500: 1.400645 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 114600: 1.402322 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.98\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 114700: 1.375146 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.52\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 114800: 1.377114 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.81\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 114900: 1.374827 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.94\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 115000: 1.373071 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.93\n",
      "================================================================================\n",
      "ame the saus that it is here is noumman held ama vb mal was not be surface log m|\n",
      "n mariztelies all with most but communicial mother black and countries with more|\n",
      "x electron continued structland a p is a became here hesk of the rabitancho are |\n",
      "ken activities and dramators as a bool and settle pas dsk cygopsun are structure|\n",
      "ward long gillands he respectively concerns and anthonicazing in earth up no he |\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 115100: 1.363119 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.70\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 115200: 1.389286 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.19\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 115300: 1.390630 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.78\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 115400: 1.413132 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.74\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 115500: 1.389393 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.90\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 115600: 1.372753 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.89\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 115700: 1.380934 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.92\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 115800: 1.365180 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.44\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 115900: 1.353942 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.43\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 116000: 1.346919 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.98\n",
      "================================================================================\n",
      "fi v media the occupied to considered to those to have been ane featured of the |\n",
      "zeo jats what carbinal one of one three two offerational was while toular un and|\n",
      "won invented the standandefur beatrogical end feel for the anyon colism state th|\n",
      "onal crucation traditic rises the history of the people as if a day and the un i|\n",
      "ferning gellagh ii the single in isbn zero external links of match a son their n|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 116100: 1.376011 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.69\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 116200: 1.372022 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.22\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 116300: 1.355606 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.83\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 116400: 1.357270 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.47\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 116500: 1.351495 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.84\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 116600: 1.346265 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.75\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 116700: 1.339919 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.70\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 116800: 1.337922 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.57\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 116900: 1.328861 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.53\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 117000: 1.357801 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.88\n",
      "================================================================================\n",
      "f effuce the story chartean earlier trads in a gundannw card saip a leg zero cha|\n",
      "y one one nine one dessocial engineerise women bhone shop of gass works the exac|\n",
      " of the two zero zero five before passing s saille democracies of the other coun|\n",
      "yphe b spelanic roma jewid setzed more edhabia in sets although reploses minon i|\n",
      "ker in two threas one nine six zero one two zero zero zero also afternut because|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 117100: 1.379741 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.12\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 117200: 1.377628 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.26\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 117300: 1.385374 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.03\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 117400: 1.390271 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.50\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 117500: 1.369552 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.48\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 117600: 1.376026 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.71\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 117700: 1.380103 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.96\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 117800: 1.362445 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.00\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 117900: 1.382234 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.99\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 118000: 1.402746 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.11\n",
      "================================================================================\n",
      "mx to those reasons athms he remains the century bely chaw is forms eventual har|\n",
      "quardchier billion francor two zero zero zero face aphoserth of the day set has |\n",
      "zic detaired figures while debated traffic them reproved by combitted tockes two|\n",
      "x same directions for others fighten dje is still to vote early tood used in the|\n",
      "pack classic academics called tathers of the proon coup and hamment brasians fil|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 118100: 1.366291 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.15\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 118200: 1.350273 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.85\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 118300: 1.369583 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.61\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 118400: 1.375888 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.12\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 118500: 1.401399 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.51\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 118600: 1.420076 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.58\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 118700: 1.368034 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.52\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 118800: 1.384945 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.56\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 118900: 1.358439 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.73\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 119000: 1.393930 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.14\n",
      "================================================================================\n",
      "ple to human grand at her turn history bases is indisamru of magazyle involventi|\n",
      "jer and the countries that divided politicians the american city of porter diplo|\n",
      "d the power eight eight five zero zero zero one two the iss of martinese silous |\n",
      "chants on the gwaveson helt he wish to be salens it mest guinea baptivism to hel|\n",
      "led state music as the six commassive well in soundard elshanet for one eight th|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 119100: 1.366426 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.40\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 119200: 1.379190 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.88\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 119300: 1.338249 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.74\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 119400: 1.365842 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.35\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 119500: 1.353068 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.02\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 119600: 1.354064 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.88\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 119700: 1.388874 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 119800: 1.393228 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.31\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 119900: 1.419925 learning rate: 0.000000\n",
      "Minibatch perplexity: 3.80\n",
      "Validation set perplexity: 3.64\n",
      "Average loss at step 120000: 1.401127 learning rate: 0.000000\n",
      "Minibatch perplexity: 4.90\n",
      "================================================================================\n",
      "ler digent uniforming on the united states a deverties from at the republies sho|\n",
      "t during this player of the count brewing averages with no the distribution and |\n",
      "mank from one nine zero as people where the ed great state of a first vicelly hi|\n",
      "m edge direspribling there is a parts where five zero zero nine to name came wit|\n",
      "ard accessed mark is the definise endings analipa production students that the l|\n",
      "================================================================================\n",
      "Validation set perplexity: 3.64\n"
     ]
    }
   ],
   "source": [
    "#num_steps = 7001\n",
    "num_steps = 120001\n",
    "summary_frequency = 100\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  mean_loss = 0\n",
    "  for step in range(num_steps):\n",
    "    batches = train_batches.next()\n",
    "    feed_dict = dict()\n",
    "    for i in range(num_unrollings + 1):\n",
    "      feed_dict[train_data[i]] = batches[i]\n",
    "    _, l, predictions, lr,ots = session.run(\n",
    "      [optimizer, loss, train_prediction, learning_rate, outputs], feed_dict=feed_dict)\n",
    "    mean_loss += l\n",
    "    if step % summary_frequency == 0:\n",
    "      if step > 0:\n",
    "        mean_loss = mean_loss / summary_frequency\n",
    "      # The mean loss is an estimate of the loss over the last few batches.\n",
    "      print(\n",
    "        'Average loss at step %d: %f learning rate: %f' % (step, mean_loss, lr))\n",
    "      mean_loss = 0\n",
    "      labels = np.concatenate(list(batches)[1:])\n",
    "      print('Minibatch perplexity: %.2f' % float(\n",
    "        np.exp(logprob(predictions, labels))))\n",
    "      if step % (summary_frequency * 10) == 0:\n",
    "        # Generate some samples.\n",
    "        print('=' * 80)\n",
    "        for _ in range(5):\n",
    "          feed = sample(random_distribution())\n",
    "          sentence = characters(feed)[0]\n",
    "          reset_sample_state.run()\n",
    "          for _ in range(79):\n",
    "            prediction = sample_prediction.eval({sample_input: feed})\n",
    "            feed = sample(prediction)\n",
    "            sentence += characters(feed)[0]\n",
    "          sentence += '|'\n",
    "          print(sentence)\n",
    "        print('=' * 80)\n",
    "      # Measure validation set perplexity.\n",
    "      reset_sample_state.run()\n",
    "      valid_logprob = 0\n",
    "      for _ in range(valid_size):\n",
    "        b = valid_batches.next()\n",
    "        predictions = sample_prediction.eval({sample_input: b[0]})\n",
    "        valid_logprob = valid_logprob + logprob(predictions, b[1])\n",
    "      print('Validation set perplexity: %.2f' % float(np.exp(\n",
    "        valid_logprob / valid_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4eErTCTybtph"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "\n",
    "We want to train a LSTM over bigrams, that is pairs of consecutive characters like 'ab' instead of single characters like 'a'. Since the number of possible bigrams is large, feeding them directly to the LSTM using 1-hot encodings will lead to a very sparse representation that is very wasteful computationally.\n",
    "\n",
    "a- Introduce an embedding lookup on the inputs, and feed the embeddings to the LSTM cell instead of the inputs themselves.\n",
    "\n",
    "b- Write a bigram-based LSTM, modeled on the character LSTM above.\n",
    "\n",
    "c- Introduce Dropout. For best practices on how to use Dropout in LSTMs, refer to this [article](http://arxiv.org/abs/1409.2329).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5tapX3kpcqZ"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "\n",
    "(difficult!)\n",
    "\n",
    "Write a sequence-to-sequence LSTM which mirrors all the words in a sentence. For example, if your input is:\n",
    "\n",
    "    the quick brown fox\n",
    "    \n",
    "the model should attempt to output:\n",
    "\n",
    "    eht kciuq nworb xof\n",
    "    \n",
    "Refer to the lecture on how to put together a sequence-to-sequence model, as well as [this article](http://arxiv.org/abs/1409.3215) for best practices.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "default_view": {},
   "name": "6_lstm.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
